{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867c1463",
   "metadata": {},
   "source": [
    "# üß† Workshop: Build a Coding LLM from Scratch\n",
    "## Part IV: Post-Training (Supervised Fine-Tuning)\n",
    "### üéØ Focus: Teaching the Model to Follow Instructions with Reasoning\n",
    "\n",
    "**Auteur :** √âquipe IRA\n",
    "\n",
    "**Date :** 1 D√©cembre 2025\n",
    "\n",
    "**Contexte :** Ce notebook d√©montre le **Post-Training** d'un mod√®le pr√©-entra√Æn√© pour qu'il suive des instructions et g√©n√®re du code avec raisonnement. Nous utilisons un dataset structur√© instruction‚Üíreasoning‚Üícode pour apprendre au mod√®le √† comprendre les consignes et √† raisonner avant de coder.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table des mati√®res\n",
    "\n",
    "1. **Introduction th√©orique** : Qu'est-ce que le Post-Training ?\n",
    "2. **R√©cup√©ration des artefacts du Pre-Training**\n",
    "3. **Chargement et exploration du dataset SFT**\n",
    "4. **Pr√©paration et encodage des donn√©es**\n",
    "5. **Chargement du mod√®le pr√©-entra√Æn√©**\n",
    "6. **Boucle de Post-Training (SFT)**\n",
    "7. **√âvaluation et tests**\n",
    "8. **Sauvegarde finale**\n",
    "9. **Comparaison Pre-Training vs Post-Training**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9b8e5",
   "metadata": {},
   "source": [
    "## üîπ Partie 1 : Introduction Th√©orique\n",
    "\n",
    "### Qu'est-ce que le Post-Training ?\n",
    "\n",
    "Le **Post-Training** (ou **Supervised Fine-Tuning - SFT**) est la phase o√π un mod√®le pr√©-entra√Æn√© apprend √† suivre des instructions sp√©cifiques.\n",
    "\n",
    "### Diff√©rence Pre-Training vs Post-Training\n",
    "\n",
    "| Aspect | Pre-Training | Post-Training (SFT) |\n",
    "|--------|--------------|---------------------|\n",
    "| **Donn√©es** | Code brut (non structur√©) | Paires instruction‚Üícode structur√©es |\n",
    "| **Objectif** | Apprendre la syntaxe Python | Suivre des consignes pr√©cises |\n",
    "| **Format** | Texte continu | Format question-r√©ponse |\n",
    "| **Exemple entr√©e** | `def fibonacci(n):...` | `\"√âcris une fonction fibonacci\"` |\n",
    "| **Exemple sortie** | Token suivant | Fonction compl√®te avec raisonnement |\n",
    "\n",
    "### Notre Dataset SFT\n",
    "\n",
    "Format : **Instruction ‚Üí Reasoning ‚Üí Code**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"instruction\": \"Return sum of even numbers up to n\",\n",
    "  \"reasoning\": \"Iterate and sum numbers divisible by 2\",\n",
    "  \"answer\": \"def sum_even_1_to_n(n):\\n    return sum(i for i in range(2, n+1, 2))\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Avantages** :\n",
    "- ‚úÖ Le mod√®le apprend √† **comprendre les consignes**\n",
    "- ‚úÖ Le mod√®le apprend √† **raisonner** avant de coder\n",
    "- ‚úÖ Le code g√©n√©r√© est **align√©** avec les besoins humains\n",
    "\n",
    "### Pipeline Post-Training\n",
    "\n",
    "```\n",
    "Mod√®le Pr√©-entra√Æn√© ‚Üí SFT Dataset ‚Üí Fine-Tuning ‚Üí Mod√®le Instruit\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f46bec",
   "metadata": {},
   "source": [
    "## üîπ Partie 2 : R√©cup√©ration des Artefacts du Pre-Training\n",
    "\n",
    "Nous r√©cup√©rons le mod√®le et le tokenizer cr√©√©s dans le notebook **Pre-Training**.\n",
    "\n",
    "### Fichiers n√©cessaires :\n",
    "- ‚úÖ `models/pre_training/mini_gpt_code_FINAL.pt` - Mod√®le pr√©-entra√Æn√©\n",
    "- ‚úÖ `models/pre_training/tokenizer/` - Tokenizer GPT-2\n",
    "- ‚úÖ Architecture `MiniGPT` (d√©finie dans le notebook pr√©c√©dent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136a0fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Device utilis√© : cuda\n",
      "üî• PyTorch version : 2.3.1\n",
      "\n",
      "üìÇ V√©rification des fichiers du Pre-Training...\n",
      "   ‚ùå models/pre_training/mini_gpt_code_FINAL.pt\n",
      "   ‚úÖ models/pre_training/tokenizer/tokenizer_config.json\n",
      "\n",
      "‚ö†Ô∏è  ATTENTION : Certains fichiers du Pre-Training sont manquants!\n",
      "   Veuillez d'abord ex√©cuter le notebook 'notebook.ipynb' (Pre-Training)\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 1: Imports et Configuration\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS DES BIBLIOTH√àQUES N√âCESSAIRES\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION POUR LA REPRODUCTIBILIT√â\n",
    "# ============================================================================\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ============================================================================\n",
    "# D√âTECTION DU DEVICE\n",
    "# ============================================================================\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üöÄ Device utilis√© : {device}\")\n",
    "print(f\"üî• PyTorch version : {torch.__version__}\")\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAM√àTRES DU POST-TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "# V√©rifier que les fichiers du pre-training existent\n",
    "required_files = [\n",
    "    \"models/pre_training/mini_gpt_code_FINAL.pt\",\n",
    "    \"models/pre_training/tokenizer/tokenizer_config.json\"\n",
    "]\n",
    "\n",
    "print(\"\\nüìÇ V√©rification des fichiers du Pre-Training...\")\n",
    "all_exist = True\n",
    "for file in required_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {file}\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "if not all_exist:\n",
    "    print(\"\\n‚ö†Ô∏è  ATTENTION : Certains fichiers du Pre-Training sont manquants!\")\n",
    "    print(\"   Veuillez d'abord ex√©cuter le notebook 'notebook.ipynb' (Pre-Training)\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Tous les fichiers n√©cessaires sont pr√©sents!\")\n",
    "\n",
    "# Hyperparam√®tres sp√©cifiques au Post-Training\n",
    "BATCH_SIZE = 8           # Plus petit batch pour SFT (donn√©es plus riches)\n",
    "N_EPOCHS = 5             # Plus d'√©poques pour bien apprendre les instructions\n",
    "LEARNING_RATE = 1e-4     # Learning rate plus faible (fine-tuning)\n",
    "MAX_LENGTH = 256         # Longueur max des s√©quences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f1fadd",
   "metadata": {},
   "source": [
    "## üîπ Partie 3 : Chargement et Exploration du Dataset SFT\n",
    "\n",
    "Notre dataset contient **10,000 exemples** de code Python avec instructions et raisonnement.\n",
    "\n",
    "### Structure des donn√©es :\n",
    "- **instruction** : Ce que l'utilisateur demande\n",
    "- **reasoning** : Le raisonnement pour r√©soudre le probl√®me\n",
    "- **answer** : Le code Python correspondant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04491363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Chargement du dataset SFT (data/python_reasoning_dataset.jsonl)...\n",
      "‚ö†Ô∏è Ligne vide ignor√©e (ligne 10380)\n",
      "‚ö†Ô∏è Ligne vide ignor√©e (ligne 10381)\n",
      "‚ö†Ô∏è Ligne vide ignor√©e (ligne 10382)\n",
      "\n",
      "‚úÖ Dataset charg√© : 10,379 exemples valides\n",
      "\n",
      "\n",
      "üìä Statistiques du dataset :\n",
      "   - Instruction moyenne : 34.3 caract√®res\n",
      "   - Reasoning moyen     : 33.0 caract√®res\n",
      "   - Answer moyen        : 80.5 caract√®res\n",
      "\n",
      "--- üìã Exemples du dataset ---\n",
      "\n",
      "Exemple 1:\n",
      "  Instruction: Return sum of even numbers up to n\n",
      "  Reasoning:   Iterate and sum numbers divisible by 2\n",
      "  Answer:      def sum_even_1_to_n(n):\\n    return sum(i for i in range(2, n+1, 2))...\n",
      "\n",
      "Exemple 2:\n",
      "  Instruction: Return all prime numbers up to n\n",
      "  Reasoning:   Check each number for primality\n",
      "  Answer:      def primes_up_to(n):\\n    def is_prime(x):\\n        if x<2: return False\\n        for i in range(2,i...\n",
      "\n",
      "Exemple 3:\n",
      "  Instruction: Return all prime numbers up to n\n",
      "  Reasoning:   Check each number for primality\n",
      "  Answer:      def primes_up_to(n):\\n    def is_prime(x):\\n        if x<2: return False\\n        for i in range(2,i...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 2: Chargement du Dataset SFT\n",
    "\n",
    "print(\"üì• Chargement du dataset SFT (data/python_reasoning_dataset.jsonl)...\")\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGEMENT DU FICHIER JSONL\n",
    "# ============================================================================\n",
    "# Chaque ligne est un objet JSON\n",
    "sft_data = []\n",
    "dataset_path = \"data/python_reasoning_dataset.jsonl\"\n",
    "\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f, start=1):\n",
    "        line = line.strip()\n",
    "\n",
    "        # Ignorer les lignes vides\n",
    "        if not line:\n",
    "            print(f\"‚ö†Ô∏è Ligne vide ignor√©e (ligne {idx})\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            example = json.loads(line)\n",
    "            sft_data.append(example)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ùå Ligne JSON invalide √† la ligne {idx}: {e}\")\n",
    "            print(\"   ‚û§ Contenu :\", line[:200])\n",
    "            continue\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset charg√© : {len(sft_data):,} exemples valides\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPLORATION DU DATASET\n",
    "# ============================================================================\n",
    "print(\"\\nüìä Statistiques du dataset :\")\n",
    "\n",
    "# Compter les longueurs\n",
    "instruction_lengths = [len(ex['instruction']) for ex in sft_data]\n",
    "reasoning_lengths = [len(ex['reasoning']) for ex in sft_data]\n",
    "answer_lengths = [len(ex['answer']) for ex in sft_data]\n",
    "\n",
    "print(f\"   - Instruction moyenne : {np.mean(instruction_lengths):.1f} caract√®res\")\n",
    "print(f\"   - Reasoning moyen     : {np.mean(reasoning_lengths):.1f} caract√®res\")\n",
    "print(f\"   - Answer moyen        : {np.mean(answer_lengths):.1f} caract√®res\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "print(\"\\n--- üìã Exemples du dataset ---\\n\")\n",
    "for i in range(3):\n",
    "    ex = sft_data[i]\n",
    "    print(f\"Exemple {i+1}:\")\n",
    "    print(f\"  Instruction: {ex['instruction']}\")\n",
    "    print(f\"  Reasoning:   {ex['reasoning']}\")\n",
    "    print(f\"  Answer:      {ex['answer'][:100]}...\")  # Tronquer pour affichage\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd9890",
   "metadata": {},
   "source": [
    "## üîπ Partie 4 : Pr√©paration et Encodage des Donn√©es\n",
    "\n",
    "### Format d'entra√Ænement\n",
    "\n",
    "Nous cr√©ons un format structur√© pour que le mod√®le apprenne :\n",
    "```\n",
    "<instruction> {instruction} <reasoning> {reasoning} <answer> {answer}\n",
    "```\n",
    "\n",
    "Ce format permet au mod√®le de distinguer les diff√©rentes parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c923554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ Chargement du tokenizer pr√©-entra√Æn√©...\n",
      "‚úÖ Tokenizer charg√© (vocabulaire : 50,254 tokens)\n",
      "‚úÖ 3 tokens sp√©ciaux ajout√©s\n",
      "üìö Nouvelle taille du vocabulaire : 50,280\n",
      "\n",
      "üîñ Tokens sp√©ciaux :\n",
      "   <instruction> ‚Üí ID 50277\n",
      "   <reasoning>   ‚Üí ID 50278\n",
      "   <answer>      ‚Üí ID 50279\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 3: Chargement du Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"üî§ Chargement du tokenizer pr√©-entra√Æn√©...\")\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGER LE TOKENIZER SAUVEGARD√â\n",
    "# ============================================================================\n",
    "# Utiliser le m√™me tokenizer que le Pre-Training\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(f\"‚úÖ Tokenizer charg√© (vocabulaire : {vocab_size:,} tokens)\")\n",
    "\n",
    "# ============================================================================\n",
    "# AJOUTER DES TOKENS SP√âCIAUX POUR LE SFT\n",
    "# ============================================================================\n",
    "# Tokens sp√©ciaux pour structurer le format instruction-reasoning-answer\n",
    "special_tokens = {\n",
    "    'additional_special_tokens': ['<instruction>', '<reasoning>', '<answer>']\n",
    "}\n",
    "\n",
    "num_added = tokenizer.add_special_tokens(special_tokens)\n",
    "print(f\"‚úÖ {num_added} tokens sp√©ciaux ajout√©s\")\n",
    "print(f\"üìö Nouvelle taille du vocabulaire : {len(tokenizer):,}\")\n",
    "\n",
    "# Afficher les IDs des nouveaux tokens\n",
    "print(\"\\nüîñ Tokens sp√©ciaux :\")\n",
    "print(f\"   <instruction> ‚Üí ID {tokenizer.encode('<instruction>', add_special_tokens=False)[0]}\")\n",
    "print(f\"   <reasoning>   ‚Üí ID {tokenizer.encode('<reasoning>', add_special_tokens=False)[0]}\")\n",
    "print(f\"   <answer>      ‚Üí ID {tokenizer.encode('<answer>', add_special_tokens=False)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0b0a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cr√©ation des datasets SFT...\n",
      "   - Train : 9,341 exemples\n",
      "   - Val   : 1,038 exemples\n",
      "\n",
      "‚úÖ Datasets cr√©√©s\n",
      "üì¶ Train batches : 1167\n",
      "üì¶ Val batches   : 129\n",
      "\n",
      "--- üß™ Test d'encodage ---\n",
      "Shape input  : torch.Size([255])\n",
      "Shape target : torch.Size([255])\n",
      "\n",
      "D√©codage de l'input :\n",
      "<instruction> Return sum of even numbers up to n <reasoning> Iterate and sum numbers divisible by 2 <answer> def sum_even_1_to_n(n):\\n    return sum(i for i in range(2, n+1, 2))<|endoftext|><|endoftex...\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 4: Cr√©ation du Dataset PyTorch pour SFT\n",
    "\n",
    "# ============================================================================\n",
    "# CLASSE DATASET POUR POST-TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "class SFTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset pour Supervised Fine-Tuning\n",
    "    Encode les exemples au format: <instruction> ... <reasoning> ... <answer> ...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, tokenizer, max_length=256):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (list): Liste de dictionnaires {instruction, reasoning, answer}\n",
    "            tokenizer: Tokenizer GPT-2\n",
    "            max_length (int): Longueur maximale des s√©quences\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retourne une s√©quence encod√©e pour l'entra√Ænement\n",
    "        \"\"\"\n",
    "        example = self.data[idx]\n",
    "        \n",
    "        # ====================================================================\n",
    "        # FORMAT: <instruction> X <reasoning> Y <answer> Z\n",
    "        # ====================================================================\n",
    "        text = (\n",
    "            f\"<instruction> {example['instruction']} \"\n",
    "            f\"<reasoning> {example['reasoning']} \"\n",
    "            f\"<answer> {example['answer']}\"\n",
    "        )\n",
    "        \n",
    "        # Encoder le texte complet\n",
    "        encoded = self.tokenizer.encode(text, add_special_tokens=False)\n",
    "        \n",
    "        # Tronquer ou padder √† max_length\n",
    "        if len(encoded) > self.max_length:\n",
    "            encoded = encoded[:self.max_length]\n",
    "        else:\n",
    "            # Padding avec eos_token\n",
    "            encoded = encoded + [self.tokenizer.eos_token_id] * (self.max_length - len(encoded))\n",
    "        \n",
    "        # Cr√©er input et target (d√©cal√© de 1 pour CLM)\n",
    "        input_ids = torch.tensor(encoded[:-1], dtype=torch.long)   # Tous sauf le dernier\n",
    "        target_ids = torch.tensor(encoded[1:], dtype=torch.long)   # Tous sauf le premier\n",
    "        \n",
    "        return input_ids, target_ids\n",
    "\n",
    "# ============================================================================\n",
    "# CR√âER LES DATASETS TRAIN/VAL\n",
    "# ============================================================================\n",
    "print(\"üìÇ Cr√©ation des datasets SFT...\")\n",
    "\n",
    "# Split 90/10\n",
    "split_idx = int(0.9 * len(sft_data))\n",
    "train_data = sft_data[:split_idx]\n",
    "val_data = sft_data[split_idx:]\n",
    "\n",
    "print(f\"   - Train : {len(train_data):,} exemples\")\n",
    "print(f\"   - Val   : {len(val_data):,} exemples\")\n",
    "\n",
    "# Cr√©er les datasets\n",
    "train_dataset = SFTDataset(train_data, tokenizer, MAX_LENGTH)\n",
    "val_dataset = SFTDataset(val_data, tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Cr√©er les DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets cr√©√©s\")\n",
    "print(f\"üì¶ Train batches : {len(train_loader)}\")\n",
    "print(f\"üì¶ Val batches   : {len(val_loader)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST D'ENCODAGE\n",
    "# ============================================================================\n",
    "print(\"\\n--- üß™ Test d'encodage ---\")\n",
    "test_input, test_target = train_dataset[0]\n",
    "print(f\"Shape input  : {test_input.shape}\")\n",
    "print(f\"Shape target : {test_target.shape}\")\n",
    "print(f\"\\nD√©codage de l'input :\")\n",
    "print(tokenizer.decode(test_input.tolist())[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544363a",
   "metadata": {},
   "source": [
    "## üîπ Partie 5 : Chargement du Mod√®le Pr√©-Entra√Æn√©\n",
    "\n",
    "Nous chargeons le **MiniGPT pr√©-entra√Æn√©** depuis le checkpoint sauvegard√©.\n",
    "\n",
    "‚ö†Ô∏è **Important** : Nous devons **red√©finir l'architecture** car elle n'est pas sauvegard√©e dans le checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52233101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Architecture red√©finie\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 5: Red√©finition de l'Architecture MiniGPT\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "# ============================================================================\n",
    "# COPIE DE L'ARCHITECTURE DU PRE-TRAINING\n",
    "# ============================================================================\n",
    "# On doit red√©finir toutes les classes car elles ne sont pas dans le checkpoint\n",
    "\n",
    "class CausalSelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads, block_size):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "\n",
    "        self.qkv = torch.nn.Linear(d_model, 3 * d_model)\n",
    "        self.proj = torch.nn.Linear(d_model, d_model)\n",
    "\n",
    "        mask = torch.tril(torch.ones(block_size, block_size)).view(1, 1, block_size, block_size)\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = qkv.split(C, dim=2)\n",
    "        q = q.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        att = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float(\"-inf\"))\n",
    "        att = torch.nn.functional.softmax(att, dim=-1)\n",
    "        y = att @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        return self.proj(y)\n",
    "\n",
    "class Block(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, block_size):\n",
    "        super().__init__()\n",
    "        self.ln1 = torch.nn.LayerNorm(d_model)\n",
    "        self.attn = CausalSelfAttention(d_model, n_heads, block_size)\n",
    "        self.ln2 = torch.nn.LayerNorm(d_model)\n",
    "        self.ff = torch.nn.Sequential(\n",
    "            torch.nn.Linear(d_model, d_ff),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class TinyDecoderLM(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        # ‚úÖ Embeddings\n",
    "        self.tok_emb = torch.nn.Embedding(cfg.vocab_size, cfg.d_model)\n",
    "        self.pos_emb = torch.nn.Embedding(cfg.block_size, cfg.d_model)\n",
    "        # ‚úÖ Transformer blocks (8 blocks)\n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "            Block(cfg.d_model, cfg.n_heads, cfg.d_ff, cfg.block_size)\n",
    "            for _ in range(cfg.n_layers)\n",
    "        ])\n",
    "        # ‚úÖ Final layer norm and head\n",
    "        self.ln_f = torch.nn.LayerNorm(cfg.d_model)\n",
    "        self.head = torch.nn.Linear(cfg.d_model, cfg.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        \"\"\"\n",
    "        Forward pass avec support optionnel du calcul de loss\n",
    "        \n",
    "        Args:\n",
    "            idx: input token ids (B, T)\n",
    "            targets: target token ids pour CLM (B, T) - optionnel\n",
    "            \n",
    "        Returns:\n",
    "            logits: (B, T, vocab_size)\n",
    "            loss: scalar tensor si targets est fourni, sinon None\n",
    "        \"\"\"\n",
    "        B, T = idx.shape\n",
    "        pos = torch.arange(0, T, device=idx.device).unsqueeze(0)\n",
    "        x = self.tok_emb(idx) + self.pos_emb(pos)\n",
    "        \n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        \n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)  # (B, T, vocab_size)\n",
    "        \n",
    "        # Calculer la loss si targets est fourni\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # Reshape pour cross_entropy\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, self.cfg.vocab_size),\n",
    "                targets.view(-1),\n",
    "                ignore_index=-100\n",
    "            )\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        G√©n√©ration de tokens de mani√®re autoregressive\n",
    "        \n",
    "        Args:\n",
    "            idx: (B, T) initial token ids\n",
    "            max_new_tokens: nombre de tokens √† g√©n√©rer\n",
    "            temperature: contr√¥le la randomness (> 1 = plus random)\n",
    "            top_k: si fourni, sample parmi les top_k tokens\n",
    "            \n",
    "        Returns:\n",
    "            idx: (B, T + max_new_tokens) tokens g√©n√©r√©s\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Limiter √† block_size\n",
    "            idx_cond = idx[:, -self.cfg.block_size:]\n",
    "            \n",
    "            # Forward pass\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature  # (B, vocab_size)\n",
    "            \n",
    "            # Top-k sampling\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = float('-inf')\n",
    "            \n",
    "            # Softmax et sampling\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "        return idx\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. MODEL CONFIG\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    vocab_size: int = 50257\n",
    "    d_model: int = 512\n",
    "    n_heads: int = 8\n",
    "    n_layers: int = 8\n",
    "    d_ff: int = 2048\n",
    "    block_size: int = 256\n",
    "\n",
    "    \n",
    "\n",
    "print(\"‚úÖ Architecture red√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166ea921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Chargement du mod√®le pr√©-entra√Æn√©...\n",
      "\n",
      "üìä Configuration du mod√®le :\n",
      "   - Vocabulaire   : 50,257\n",
      "   - Block size    : 256\n",
      "   - d_model       : 512\n",
      "   - Attention heads: 8\n",
      "   - Layers        : 8\n",
      "   - d_ff          : 2048\n",
      "\n",
      "üîß Ajustement du vocabulaire :\n",
      "   - Ancien vocabulaire : 50,257\n",
      "   - Nouveau vocabulaire: 50,280\n",
      "   - Tokens ajout√©s     : 23\n",
      "Cl√©s du checkpoint: ['tok_emb.weight', 'pos_emb.weight', 'blocks.0.ln1.weight', 'blocks.0.ln1.bias', 'blocks.0.attn.mask']...\n",
      "\n",
      "‚úÖ Mod√®le charg√© avec 76,837,888 param√®tres\n",
      "üìà Validation loss du pre-training : N/A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TinyDecoderLM(\n",
       "  (tok_emb): Embedding(50280, 512)\n",
       "  (pos_emb): Embedding(256, 512)\n",
       "  (blocks): ModuleList(\n",
       "    (0-7): 8 x Block(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=512, out_features=50280, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Cell 6: Chargement du Mod√®le Pr√©-Entra√Æn√©\n",
    "\n",
    "print(\"üì• Chargement du mod√®le pr√©-entra√Æn√©...\")\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGER LE CHECKPOINT\n",
    "# ============================================================================\n",
    "checkpoint = torch.load(\"models/pre_training/model_final.pt\", map_location=device)\n",
    "\n",
    "# R√©cup√©rer la configuration\n",
    "pretrained_state = checkpoint\n",
    "config = ModelConfig()\n",
    "print(f\"\\nüìä Configuration du mod√®le :\")\n",
    "print(f\"   - Vocabulaire   : {config.vocab_size:,}\")\n",
    "print(f\"   - Block size    : {config.block_size}\")\n",
    "print(f\"   - d_model       : {config.d_model}\")\n",
    "print(f\"   - Attention heads: {config.n_heads}\")\n",
    "print(f\"   - Layers        : {config.n_layers}\")\n",
    "print(f\"   - d_ff          : {config.d_ff}\")\n",
    "\n",
    "# ============================================================================\n",
    "# INSTANCIER LE MOD√àLE AVEC LA NOUVELLE TAILLE DE VOCABULAIRE\n",
    "# ============================================================================\n",
    "# IMPORTANT: Le vocabulaire a augment√© avec les tokens sp√©ciaux !\n",
    "new_vocab_size = len(tokenizer)\n",
    "\n",
    "print(f\"\\nüîß Ajustement du vocabulaire :\")\n",
    "print(f\"   - Ancien vocabulaire : {config.vocab_size:,}\")\n",
    "print(f\"   - Nouveau vocabulaire: {new_vocab_size:,}\")\n",
    "print(f\"   - Tokens ajout√©s     : {new_vocab_size - config.vocab_size:,}\")\n",
    "\n",
    "# Cr√©er le mod√®le avec le NOUVEAU vocabulaire\n",
    "config.vocab_size = new_vocab_size\n",
    "model = TinyDecoderLM(config).to(device)\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGER LES POIDS PR√â-ENTRA√éN√âS\n",
    "# ============================================================================\n",
    "# Les embeddings ont une taille diff√©rente, on doit les ajuster\n",
    "print(f\"Cl√©s du checkpoint: {list(pretrained_state.keys())[:5]}...\")\n",
    "\n",
    "# R√©cup√©rer les anciens embeddings\n",
    "old_token_emb = pretrained_state['tok_emb.weight']\n",
    "old_vocab_size, emb_dim = old_token_emb.shape\n",
    "\n",
    "# Cr√©er de nouveaux embeddings (avec les tokens sp√©ciaux)\n",
    "new_token_emb = model.tok_emb.weight.data.clone()\n",
    "\n",
    "# Copier les anciens poids\n",
    "new_token_emb[:old_vocab_size] = old_token_emb\n",
    "\n",
    "# Mettre √† jour le state_dict\n",
    "pretrained_state['tok_emb.weight'] = new_token_emb\n",
    "pretrained_state['head.weight'] = new_token_emb  # Weight tying\n",
    "\n",
    "# Charger les poids\n",
    "model.load_state_dict(pretrained_state, strict=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Mod√®le charg√© avec {sum(p.numel() for p in model.parameters()):,} param√®tres\")\n",
    "print(f\"üìà Validation loss du pre-training : {checkpoint.get('best_val_loss', 'N/A')}\")\n",
    "\n",
    "# Mettre en mode entra√Ænement\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e57591c",
   "metadata": {},
   "source": [
    "## üîπ Partie 6 : Boucle de Post-Training (SFT)\n",
    "\n",
    "Nous fine-tunons le mod√®le sur les donn√©es d'instructions.\n",
    "\n",
    "### Strat√©gie d'entra√Ænement :\n",
    "- Learning rate plus faible (1e-4 vs 3e-4 en pre-training)\n",
    "- Plus d'√©poques (5 vs 3)\n",
    "- Monitoring de la qualit√© des r√©ponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70394657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration de l'optimisation termin√©e\n",
      "üìä Total steps : 5,835\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 7: Configuration de l'Optimisation\n",
    "\n",
    "# ============================================================================\n",
    "# OPTIMIZER ET SCHEDULER\n",
    "# ============================================================================\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE,  # 1e-4 (plus faible que pre-training)\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "total_steps = len(train_loader) * N_EPOCHS\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION D'√âVALUATION\n",
    "# ============================================================================\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, max_batches=50):\n",
    "    \"\"\"Calcule la loss moyenne sur la validation\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(val_loader):\n",
    "        if batch_idx >= max_batches:\n",
    "            break\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        _, loss = model(x, y)\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "    \n",
    "    model.train()\n",
    "    return total_loss / count if count > 0 else 0\n",
    "\n",
    "# ============================================================================\n",
    "# HISTORIQUE DES M√âTRIQUES\n",
    "# ============================================================================\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'epochs': []\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration de l'optimisation termin√©e\")\n",
    "print(f\"üìä Total steps : {total_steps:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798f65b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ D√©but du Post-Training (SFT)...\n",
      "üìä Configuration: 5 √©poques, 1167 batches/√©poque\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìÖ √âpoque 1/5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ddce9b2edb4a729426faebe7a5403c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SFT Epoch 1:   0%|          | 0/1167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Fin √âpoque 1:\n",
      "   - Train Loss: 0.0137\n",
      "   - Val Loss:   0.0121\n",
      "   - Perplexity: 1.01\n",
      "\n",
      "üéØ Test de g√©n√©ration (epoch 1):\n",
      "<instruction> Write a function to calculate factorial <reasoning> Check each number for primality <answer> def primes_n):\\n    def(n    def is_prime(x):\\n        if x<2: return False\\n        for i in range(2,int(x**0.5)+1):\\n            if x%i==0: return False\\n        return True\\n    return [i for i in range(2,n+1) if is_prime(i)]<|endoftext|><|endoftext|>\n",
      "\n",
      "üíæ Checkpoint SFT sauvegard√© : models/post_training/model_sft_epoch_1.pt\n",
      "\n",
      "============================================================\n",
      "üìÖ √âpoque 2/5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0295f40b8c35434e982ba1e0b9ed860c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SFT Epoch 2:   0%|          | 0/1167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Fin √âpoque 2:\n",
      "   - Train Loss: 0.0117\n",
      "   - Val Loss:   0.0116\n",
      "   - Perplexity: 1.01\n",
      "\n",
      "üéØ Test de g√©n√©ration (epoch 2):\n",
      "<instruction> Write a function to calculate factorial <reasoning> Use max function <answer> def largest(lst):\\n    return max(lst)<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "\n",
      "üíæ Checkpoint SFT sauvegard√© : models/post_training/model_sft_epoch_2.pt\n",
      "\n",
      "============================================================\n",
      "üìÖ √âpoque 3/5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abee3b99f1d48339168bbe430a67d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SFT Epoch 3:   0%|          | 0/1167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Fin √âpoque 3:\n",
      "   - Train Loss: 0.0115\n",
      "   - Val Loss:   0.0115\n",
      "   - Perplexity: 1.01\n",
      "\n",
      "üéØ Test de g√©n√©ration (epoch 3):\n",
      "<instruction> Write a function to calculate factorial <reasoning> Check if n <answer> def is_s(n):\\n    return s[::-1]<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "\n",
      "üíæ Checkpoint SFT sauvegard√© : models/post_training/model_sft_epoch_3.pt\n",
      "\n",
      "============================================================\n",
      "üìÖ √âpoque 4/5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b9079eafa54b88abc5a121febe3237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SFT Epoch 4:   0%|          | 0/1167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Fin √âpoque 4:\n",
      "   - Train Loss: 0.0115\n",
      "   - Val Loss:   0.0115\n",
      "   - Perplexity: 1.01\n",
      "\n",
      "üéØ Test de g√©n√©ration (epoch 4):\n",
      "<instruction> Write a function to calculate factorial <reasoning> Check each number for primality <answer> def primes_up_to(n):\\n    def is_prime(x):\\n        if x<2: return False\\n        for i in range(2,int(x**0.5)+1):\\n            if x%i==0: return False\\n        return True\\n    return [i for i in range(2,n+1) if is_prime(i)]<|endoftext|><|endoftext|>\n",
      "\n",
      "üíæ Checkpoint SFT sauvegard√© : models/post_training/model_sft_epoch_4.pt\n",
      "\n",
      "============================================================\n",
      "üìÖ √âpoque 5/5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdee6ee2dd7c45e190057d774013bf82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SFT Epoch 5:   0%|          | 0/1167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Fin √âpoque 5:\n",
      "   - Train Loss: 0.0117\n",
      "   - Val Loss:   0.0117\n",
      "   - Perplexity: 1.01\n",
      "\n",
      "üéØ Test de g√©n√©ration (epoch 5):\n",
      "<instruction> Write a function to calculate factorial <reasoning> Check if n <answer> def is_(n):\\n    return(lst)<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "\n",
      "üíæ Checkpoint SFT sauvegard√© : models/post_training/model_sft_epoch_5.pt\n",
      "\n",
      "‚úÖ Post-Training termin√© !\n",
      "üìÅ 5 checkpoints SFT sauvegard√©s dans models/post_training/\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 8: Boucle de Post-Training\n",
    "\n",
    "print(\"üöÄ D√©but du Post-Training (SFT)...\")\n",
    "print(f\"üìä Configuration: {N_EPOCHS} √©poques, {len(train_loader)} batches/√©poque\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# BOUCLE D'ENTRA√éNEMENT\n",
    "# ============================================================================\n",
    "model.train()\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìÖ √âpoque {epoch+1}/{N_EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"SFT Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(pbar):\n",
    "        # D√©placer sur device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, loss = model(x, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Logging\n",
    "        epoch_loss += loss.item()\n",
    "        global_step += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'avg_loss': f'{epoch_loss/(batch_idx+1):.4f}',\n",
    "            'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "        })\n",
    "    \n",
    "    # M√©triques de fin d'√©poque\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    \n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['epochs'].append(epoch + 1)\n",
    "    \n",
    "    print(f\"\\nüìä Fin √âpoque {epoch+1}:\")\n",
    "    print(f\"   - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"   - Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"   - Perplexity: {np.exp(val_loss):.2f}\")\n",
    "    \n",
    "    # Test de g√©n√©ration\n",
    "    print(f\"\\nüéØ Test de g√©n√©ration (epoch {epoch+1}):\")\n",
    "    test_prompt = \"<instruction> Write a function to calculate factorial <reasoning>\"\n",
    "    test_ids = torch.tensor([tokenizer.encode(test_prompt)], device=device)\n",
    "    generated = model.generate(test_ids, max_new_tokens=100, temperature=0.7, top_k=50)\n",
    "    print(tokenizer.decode(generated[0].tolist()))\n",
    "    print()\n",
    "    \n",
    "    # Sauvegarde du checkpoint\n",
    "    os.makedirs(\"checkpoints_sft\", exist_ok=True)\n",
    "    checkpoint_sft = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'history': history,\n",
    "        'config': {\n",
    "            'vocab_size': new_vocab_size,\n",
    "            'block_size': config.block_size,\n",
    "            'd_model': config.d_model,\n",
    "            'n_head': config.n_heads,\n",
    "            'n_layer': config.n_layers,\n",
    "            'd_ff': config.d_ff\n",
    "        }\n",
    "    }\n",
    "    checkpoint_path = f\"models/post_training/model_sft_epoch_{epoch+1}.pt\"\n",
    "    torch.save(checkpoint_sft, checkpoint_path)\n",
    "    print(f\"üíæ Checkpoint SFT sauvegard√© : {checkpoint_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Post-Training termin√© !\")\n",
    "print(f\"üìÅ {N_EPOCHS} checkpoints SFT sauvegard√©s dans models/post_training/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ae99b",
   "metadata": {},
   "source": [
    "## üîπ Partie 7 : Visualisation des R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92b2665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amine\\AppData\\Local\\Temp\\ipykernel_28152\\647608299.py:25: UserWarning: Glyph 128201 (\\N{CHART WITH DOWNWARDS TREND}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\amine\\AppData\\Local\\Temp\\ipykernel_28152\\647608299.py:25: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\amine\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 128201 (\\N{CHART WITH DOWNWARDS TREND}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\amine\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW4AAAHqCAYAAACUWtfDAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAArTBJREFUeJzs3XmcjfX///Hnmd02llnsxk72fZd9C0lZshNSpPApEdWgKGTJFi0mypKypLQohFAiS4sopBiGIWObYeZcvz985/rNmTlnnDNm5pwxj/vtNjdzruV9va7XOeO8z+u8r/dlMQzDEAAAAAAAAADAY3i5OwAAAAAAAAAAgC0KtwAAAAAAAADgYSjcAgAAAAAAAICHoXALAAAAAAAAAB6Gwi0AAAAAAAAAeBgKtwAAAAAAAADgYSjcAgAAAAAAAICHoXALAAAAAAAAAB6Gwi0AAAAAAAAAeBgKtwAAAAAAIM3GjBkji8WisLAwHT9+3N3hAMA9g8It4EEsFov5ExER4e5w7CpZsqQZY3h4uLvDgaTw8HDzOSlZsqS7w8lSNm7caOZu1KhR7g4n20jv1+zJkydt/v/ctm3bXbeZVg8++KAsFou8vb118OBBt8UBAPA8nvB+1bx5c/P4AwcOTJc2169fr9mzZ6tEiRLaunWrSpcu7XIbBw8elLe3tywWix566KF0iQt3FhERYfOaTA+e8pn26aefNuP47LPP3BYHcLco3MItkv5n7uinU6dOLrUZHx+vFStWqFu3bipZsqRy5cqlPHny6L777tPDDz+sFStW6Nq1axl0RpDkVCe0Xbt2Ns9zrly5dOXKlcwLMouhKJtxbt26peeee06S5O/vb/6eKOmXFEl//Pz8VKRIET344IP69NNP3RG6Bg4caMbTvHlzp/Zx5v/d5D8nT57M0PO4F7300kuSJKvVqjFjxrg5GgBwn/Ts73vye/K9JC1F3RMnTmjQoEF3VbSVbo/YtVqtkqSJEyc6jCvpj4+Pj0JDQ9W2bVstW7ZMhmGk6dh3Iy19dUev59R+3PmldFb1/PPPy9/fX5L07LPPKj4+3s0RAWnj4+4AkH0dOnRIISEhdtetXr1amzdvdqmtnj176siRIynWHTlyREeOHNG6des0e/ZsRtW50enTp/XNN9/YLLt+/bo++ugjDR482E1RZX1t27ZV7ty5JUl58+Z1czRZx7Jly/THH39Iknr27KmiRYs6td+tW7cUGRmpjRs3auPGjRo6dKiWLFmSkaHec9L7NVugQAHNmDHDfFymTJm7bjOt6tSpo6ZNm2rHjh3asmWLvv32W7Vq1cpt8QCAO6Vnf98e3pNd9+STT5oF8ypVqtx1ewcOHNAzzzyjAQMGqFSpUmlq49tvv9WWLVskSffff7/q1Knj1H4JCQk6f/68Nm/erM2bN+ujjz7SunXr5Ovrm6Y4sqO6deva9KHSQ9L26tatm65tu6Jo0aLq0aOHli9frj/++EPvv/8+nzmRJVG4hduEhISoUKFCdte58kH+999/V7NmzfTff/+Zy6pWrar27dsrf/78OnfunLZt2+axl6zGx8fr1q1bypEjh7tDyXDLli0zv0lPKiIiwuPfRA3D0LVr18xikydp1KiRGjVq5O4wspwFCxaYv/ft2zfVbUuXLq0nn3xSknTq1Cm9//77iomJkSS9/fbb6tixo7p06ZJxwaaD5J3yv/76S2+99Zb5uGfPnik+KBUoUMBhe1euXFGePHnSFEt6v2YDAwP17LPPplt7d6tPnz7asWOHpNuvMwq3ALKr9OrvJ+XO9+R7od/es2fPdG2va9eu6tq16121MX/+fPP3O/XJ8ufPrxdeeEGSdO7cOS1fvlznzp2TJH3++edauHChnnnmmbuKJ6NNmDBBly9fNh9funRJU6dONR+3adNGbdu2tdkntS+l76ZPVrlyZVWuXDlN+zriaX2y5cuXS7rdJ/P0z5yAXQbgBpKMyMhIh+uXLl1qdOzY0am2GjRoYEgyf6ZOnWpYrdYU233//ffGV199ZbPs2rVrxhtvvGE0bNjQyJs3r+Hr62sUKlTI6Ny5s/HZZ5+laOPll182jxMWFmazbuvWrTZxnDhxwlw3YMAAc3mzZs2Mv/76y+jRo4cRFBRkWCwWY+vWrWZeEn+WLl1qbN682WjatKmRK1cuI1++fEb37t2Nv/76y24ejh07ZgwfPtyoUKGCkSNHDiNHjhxGlSpVjJdeesn477//nMplUkuWLDGqVKli+Pv7G0WLFjXGjBljxMTEGGFhYWaML7/8ss0+icsTzye5ChUqmNuUL1/e5nyPHTuWYvvkOf3rr7+M2bNnG/fdd58Z1//+9z/jypUrNvstXbrUZr8bN24YL730klG6dGnDz8/PKF26tDFlyhTj5s2bNvslf37PnTtnDBkyxChUqJDh5eVlLF261Nz20qVLxpQpU4w6deoYgYGBhp+fnxEWFmYMGTLE7rkkfw2cPn3aeOyxx4zQ0FDD39/fqFatmvHxxx87PHd7P4nxpPa6PHnypPH4448bZcuWNQICAgx/f3+jSJEiRqNGjYzRo0cbv/32W4rcNWvWzAgKCjJ8fHyMfPnyGeXLlzd69OhhLFiwwGbbjz76yOjdu7dRuXJlIyQkxPD19TVy5cplVKpUyXjqqads/gaSOnTokNGpUycjT548Rp48eYy2bdsaP/30U6rnkZacp2b//v3msfLly2fEx8en2Cbpa71Zs2Y26zZv3mzzXPTr189mfXR0tPHyyy8bNWvWNPLkyWP4+fkZxYoVM3r27Gns3LkzxbFu3bplzJ4922jQoIGRN29ew9vb2yhQoIBRqVIlo1+/fsbKlSsNw0j52rb34+jvL7nkr7Gkr297648ePWpMmTLFKFeunOHr62sMGDDAMAzD2Lt3rzFs2DCjbt26RpEiRYyAgAAjICDACAsLM3r27Gns2LEjxbFTe66T/x/zww8/GO3btzfy5Mlj5MqVy2jdurVx8OBBm31OnDjhMAfJj3Xp0iVj1KhRRrFixQw/Pz+jfPnyxsKFC+3mKK2v1fPnz5vrvb29jfPnz9/x+QCAe0169vfv5j35bvtszvbbP//8c6Nx48ZGzpw5HfbbU3u/SrRu3TqjU6dORqFChQxfX18jf/78RuvWrY1PPvnEZrt///3XKFCggNnW2LFjzXVWq9Vo1qyZua5WrVpGXFycYRiGzfLE9/Kk72uOfpL2627cuGHMnTvXaNKkiZE/f37D19fXKFy4sNGtWzfj+++/T+2pTOH8+fOGt7e3IcmwWCx23zOTxpz8fffo0aOGxWIx1zdt2tRmvauf9wzDuf6wK331O0n+ukj+GSv5+i1bthgLFiwwP6sl/k0cO3bMePrpp43GjRsbxYoVM3LmzGn4+fkZRYsWNTp37mxs3LjR7rkmbdtR3gcMGGAcOXLE6Natm5E/f34jICDAaNCggd3XsKMc2PuMFh4ebpQpU8b8u5w0aZKRkJCQos2TJ08avXr1MgoUKGDkzJnTaNy4sfH111+nGr9hGEZ8fLyRN29ec/3+/fvv/IQAHobCLdwivTpyu3fvtvmPunPnzk7HEBkZaVSuXDnVN9thw4bZ7JMehdty5coZoaGhdjttSZd16NDBphOS+BMSEpKik/nJJ58YOXLkcHgeZcqUMf7++2+nczNu3Di77dSpU8coWLCgw05Fap3QXbt22bT11Vdf2XQ2J06cmGKf5Dlt2bKl3bgaNGhgxMbGmvslfwN3tF/Xrl1tjpf0+Q0ODk5RXE7seBw5csQoUaKEw3znypUrxZcESV8DpUuXNgoVKpRiP4vFYu6XHoXbc+fOGSEhIam2sWjRIrvnb++nYMGCNufUsWPHVLcPDAw0Dh06ZLPP3r17jdy5c6fYNiAgwGjdurXDv6+05Dw106dPN/dt27at3W1S+5B49epVm+O3adPGXPfrr78axYoVcxirxWIxXn31VZv2kr4+7P3Ur1/fMAz3Fm4bN25s8zjxw96MGTNSjcdisaRo29nCbb169QwfH58UbRYoUMA4e/asuY+zhdugoCCjYsWKduNcsmSJTRxpfa0mKleunLnNmjVrnHpOAOBeImVO4Ta19+S77bM5229v0aKF3faT99tTe79KSEgwevfunep76uOPP24T69q1a8113t7exp49ewzDMIw333zTXJ4zZ07jyJEj5j53W7g9d+6cUbVqVYfbeXl5GbNnz3bqeTWM2wMBEvctX7683W1SK9wahmEEBwfbPGeJ7vbznr2fxP6wOwu3yftkiX8Ta9asuWNMkyZNsmnb2cJttWrV7PaL/Pz8jF9++cVmP0c5SH6s5OeR+PPCCy+kOH9Hn50eeOABh/EnatOmjbl+xowZTj0ngCdhqgRkaYlzISV67LHHnN63T58++vXXX83HPXv2VPny5fX5559r//79kqTFixerRo0aeuKJJ9InYEnHjh2TxWJR9+7dVbVqVZ08eVK5cuVKsd0XX3yh2rVr64EHHtCvv/6qtWvXSpLOnz+vJ554wpwr9vjx4+rTp49iY2MlSdWqVdNDDz2kmzdvavny5Tp9+rT++usv9erVS99///0d49u7d69ef/1183GhQoXUv39/Xb16Ve+++67i4uIc7mukckOApHcULVy4sFq3bq2HH35Y77zzjqTb0yhMnjw51buZbtmyRV26dFH16tX1xRdfaO/evZKkPXv2aMaMGSluZJBo69at6tevn0qUKKFPPvnEnAt53bp1+uCDD+xeknXhwgVduHBB7du3V8OGDXXu3DkFBQUpISFBXbt21alTpyRJBQsWVJ8+fZQ3b1599tln2rt3r65du6YePXro2LFjdud1O378uHLmzKmRI0fKarXqrbfeUkJCggzD0BtvvKG2bduqTJkymjFjhr7++mtz/rekl4ZJd54z6pNPPtH58+fNfQcNGqSgoCCdOXNGR44cMS/lTrRo0SLz91atWqlFixa6du2a/vnnH+3cuVM3btyw2T5//vxq3769KlSooPz588vPz0/nzp3T2rVr9c8//ygmJkbPP/+8Nm3aZO4zaNAgXb161Xzcq1cvlS5dWh999FGK+Y8TpUfOk0v6t1CzZs07bp/c7t27bR4nXgYaHx+vrl276t9//5Uk+fj4aMCAASpYsKDWrFmjY8eOyTAMTZgwQTVr1lSHDh109epVffDBB2ZbjzzyiGrVqqXLly/r77//1nfffWeuS5yHbPXq1frpp58k2V4yKmXc/K7ff/+9qlWrpo4dO8pqtZqXuAYEBKhhw4aqUaOGgoKClCtXLl2+fFnffvut9u7dK8Mw9L///U89e/Z0+dLSH3/8UWFhYerVq5d+/fVXbdy4UZJ08eJFvffeexo/frxL7UVHR+u///7TY489pqCgIC1YsEDXr1+XJM2cOVNDhw41t03LazWpmjVr6tixY5Ju565bt24uxQoAcI6j9+T06D8422/funWrU/321Lz22mtasWKFJMnLy0vdu3dXlSpVdOzYMX344YdKSEjQkiVLVLt2bT3++OOSbk9T8Pjjj2vJkiVKSEjQwIEDtWbNGo0bN85sd+7cuapQoUKqx06ce37RokU6fvy4pNtztiedViFx+qS+ffvq8OHDkm5Pd9GnTx8VKlRI3333nb799lvz5px169ZV48aN73jed9snO3r0qKKjo83HSafmSMvnPWf7w+nRV0+r77//XqVLl9bDDz+sgIAAsy/j6+urWrVqqXbt2goJCVFgYKCuXr2q77//Xlu3bpUkTZkyRYMHD3b63g6JDh06pODgYD3xxBPmFBWSdPPmTb355ptavHhxms6je/fuKlu2rN59911FRUVJkubNm6eXX35Zfn5+kqSnnnpKZ8+eNfd74IEHVLt2bX3++ec2nzMcqVmzpvkcff/99x41lQPgFPfWjZFdSenzDfzw4cNtvmH7/fffnTr+zz//bLPf+PHjzXVxcXHGfffdZ64rW7asuS49RtxKcnhZbtJtKleubF7SZBiGMXToUJv1f/75p2EYhjF69GhzWdWqVW32OXLkiM0+zly6NGzYMJtv7v/44w9z3Ycffpjqt8GO3Lhxw8iXL5+53zPPPGMYRspL27755hub/ZLndOjQoea6mzdv2nyDXqxYMXNd8m9zk45uvHz5ss238kkvp0r+DXvSS84SbdiwweYb5pMnT5rr4uLibEZ1JD1u8tdA0kuzRo0aZS4vUKCAzfHudEl2atvMmjXLXJ58NIFh3B6hknTUYmBgoLm9vb9Pe9N03Lx509i+fbvx7rvvGrNnzzZmzJhhDBo0yGzH39/fnJIi+ajr559/3mzn4sWLRv78+e2eR1pznpo6deqY+7zxxht2t0k6uqd06dLGjBkzjBkzZhhPP/20Ta4kGevWrTMM4/bljUmXL1682Gzv0qVLNqPMW7dubZ574rLAwECbv2HDuH254/Hjx22WJb+MMy1cHXHbtGnTFLEldfDgQeODDz4w5s6da8yYMcN45ZVXbPbfvn27ua2zI25z585t81qsWbOmue7hhx82lzs74laSMX/+fHPdnDlzbNbFxMQYhpH212pSTz31lLlN9+7dHeYNAO5V6dXfN4y0vSenV58tPfvtjt6vEhISjKCgIHP51KlTbY6V9Gq4pCNKDeP2VABJryZJOirykUceSRG3vRG3zqwzjNvv9Unj37Vrl7nOarUaDRs2NNf16NHDbt6S69atm7nPyJEj7W6TNK78+fObz/9zzz2XYiRm4mjftH7ec7U/7Exf/U5cHXFbrlw54/Llyw7b++OPP4xVq1YZ8+bNM2bOnGnMmDHDyJkzp7n/smXLzG2dHXHr5eVlM1XVQw89ZK6rVauWzX6O+pfJj/Xss8+a69avX2+zLvGqvdOnT9tchdqzZ09zn9jYWJup+JLHn2jmzJnm+rp16zrMG+CpGHGLLM1IZYRnanbt2mXzuF+/fubvfn5+evTRR/Xyyy9Lkv7880+dP3/eqVF8zihQoID5LXlqevbsaX7LKN3+dvvtt982H+/bt09lypSx+Zb68OHD8vf3d9jmrl277nhDoMRRfNLtb9rLly9vE9PAgQN169atO8af1Lp162xuHvfoo49Kklq0aKGCBQuaNxSIiIhI9SY+SZ8nX19f9ejRw3ye/v33X0VFRSk0NDTV/QIDA9W5c2ctXbpUku35Jpd0tEKipPm+efOmSpYs6XD/5K+zREWLFlXHjh3Nx0lHQVy6dMlhe65q3LixLBaLDMPQkiVLtHfvXlWqVEkVKlRQnTp1zPwnatq0qT7//HNJt+8yXL9+fZUrV06VK1dWixYtVLZsWZv2P/zwQ40aNUoXLlxwGENcXJwuXLigwoULa9++fTbr+vfvb/6eP39+denSxWZkdqL0yHlySV+PgYGBd9z++PHjeu655+yue+yxx/TQQw/ZPX7S0dz58uVTly5dzNde4rb58+dX5cqV9euvvyomJkalSpVS3bp1Va5cOVWtWlWtWrVy+S7N//zzj1avXp1iefHixdN8U5IxY8bY/J+UaP/+/erfv7/NiBZ7Ekchu6JLly42I2fKly+vn3/+WVLa/la8vb1tbkqRfATSpUuXlCdPnjS/VpNK+rpK+noDANwdZ9+T06P/kN79dkf++OMPm1GjL7zwgs3IzaSOHTumCxcuKDg4WJKUM2dOrVy5UvXr19fNmzfNq0WKFSumJUuW3DF2VyS/ei+1zxWJI1rvxNU+2aVLlxw+/+3atdOIESMkpf3znqv94TuJiYmx+zzkzZvX5kofVwwfPtxurk6ePKk+ffrcsT+clj5Zw4YNVa1aNfNxenx+GTZsmN32kra5f/9+m8/8Sftk/v7+6tWrl8LDw1M9Dn0yZHUUbpGlFStWzObxkSNHVLFixTvul/zNJXmxL2kxK3H75IXb5EXj1KYQSKpMmTLy9va+43bOxCTdvmTYWYmXzacm6ZtZ8hi8vb0VFBRkc6mKM5IWOEqWLKkGDRqY7XXr1k0LFiyQJK1du1YLFy50eFdUZ3Jir3Cb2n43btxQXFxcioJ3SEiI8ufPn6Kt9Mh3WFiYzeOkx07rlxH21KtXT7NmzdKLL76oq1evav/+/Tad6ODgYK1Zs0bNmzeXdPvSsB49emjPnj2Kjo5OcelRjx49tHLlSnl5eZnFOqvVesc4Ev82kneUkt9l2tFdp9P7NS7dLqImSrwTtbN8fHwUHBysOnXq6LHHHrO5k3LS/1ty586tnDlz2uyb9LV3/fp13bx5U35+flqxYoV69eql3377TWfOnNGGDRvM7by8vPTMM89o1qxZTsf4119/2f1Q06xZszQXbpN+iZPoxo0b6tSpkyIjI++4v7P/RyaV2t+KM6+95AoWLKiAgAC77SVtM62v1aSSvq6Svt4AAOkntffk9Og/pHe/3RFXYpVux5tYuJWkGjVqqEmTJjbTyPXu3duc3iC9uBKnswWyu+mTeXt7K3/+/Kpevbr69OmjAQMGyMvLS1LaP++50h92xsWLF+32ycLCwtJcuLXXJ5Okhx56SAcPHrzj/p7QJ0veJn0ywDEKt8jSWrZsafM4IiLC/JY9NckLclFRUQoKCjIfJ44ATb590jfo5PN9Js5leCfJCzmOJM7x4yimxDedpOdSvXp1u/O1JnJmnqWkb2bJY0hISLAZDeCM06dP28zrdfLkSYfz2F6/fl0fffSRzYi4pKKiomy+jXWUE3v7FS9e3O5+AQEBdkcpO3qekuY7d+7c5jf19jjqSPj6+to8Tm1e37s1atQoPf7449qzZ49+/fVXHTt2TF9++aU5WmPgwIE6efKkpNujMXfv3q0///xTP/74o44dO6ZDhw7p008/VXx8vD766CN16NDBnD8tsUOVK1cuffzxx2rWrJly5MihTZs22YwoTpT8+YmKirL5QOHoC4H0yHlyRYoUMX93ptjbrFkzbdu27Y7bJY316tWrun79us1rKelrL2fOnObonGrVqunXX3/V4cOHtX//fh07dkz79+/XF198IavVqtmzZ+vBBx80i+zuYO9vYvv27TZF2xkzZmjw4MHKnz+/rl+/bnceQFek99+Ks+2l9bWafJ9Ers4jBwBwLC3vyWntP6R3v92R5J9NhgwZkuq8tMmLkMuXL09x74+5c+eqd+/eql69eqrHdkXSOC0Wiw4dOuTw3JwpeEuu98nCwsLMvmtq0vp5z5X+sLvYe13+8ccfNkXb0aNHa9y4cQoJCZHFYlFoaKjTAxzsyYjPL0nbdKVPlhR9MmQHFG6RpTVo0ED169fXDz/8IEnasGGDZsyYYfdbzd27d+vq1atq06ZNist6li9frqlTp0q6fSnVqlWrzHVly5Y1R9smfeM4f/68jh8/rtKlS+vKlSs2E9mnh9WrV2vcuHHmG1rSmxdJt6cxkG5fopR4k67IyEj17ds3ReczNjZWa9asUbNmze543Dp16piXCf/00086evSo+a3u6tWrXZ4mYdmyZS59CxsREeGwcLt8+XI1bdpUknTr1i199NFH5rpixYql+OY86X6Jl5vFxMSYNziS/n8enZX0tXP16lXVqlUrxRcIhmFoy5YtKl26tEtt25O0Q5N44wFnnTlzRt7e3ipYsKBatmxpxvnzzz+rVq1akqS///5b0dHRCgoK0sGDB1W1alWVLVvW5jKwLl266NNPP5V0+1K/gQMH2hTwS5curfbt25uPk/79JJX8i4NVq1aZlzZdunTJZpRpUhmR84YNG5rnlHjpfXpI/n/LBx98YF5i+d9//9mcY9JtDxw4oBo1aqhq1aqqWrWqubx69eo6dOiQpNu5Tyzc3ul10bx583Qdve1I8i9yHnvsMfODj6PXQVaQ1tdqUklHtztzcxYAQPrKzD6bs/12RypWrKigoCDzfTUuLs7uDZROnTql33//3aYAeeLECT311FPm4/vuu0+///674uLi1Lt3b/30009O3xz0Tv2LpDk1DEPr1q3Tiy++aLNNQkKC1q1bp+DgYBUuXPiOx2zYsKHefPNNSRnbJ3P2854r/WHpzjkrWbKkW/pkffv2NQv8W7ZsuauirTvVqVPHnPpNut0nS/zcERcXp5UrV96xDfpkyOoo3CLLe/fdd9W4cWNdvnxZkjR27Fh9+OGHat++vfLly6ezZ8/qu+++04EDBzR79my1adNGNWrUUPPmzc1v66dNm6YTJ06ofPny+uyzz/T777+b7Y8ePdr8PXmnq0mTJmrevLn27NmjEydOpOt5/frrr2rYsKE6duyoX375xbw7rXR7btjEebJGjhypt956S3FxcYqKilL16tXVo0cPFSlSRDExMTp8+LC+++47Xb161WZuJ0cee+wxLVmyRIZhKCEhQc2aNdOAAQN05coVvfvuuy6fx/vvv2/+XrBgQbsjBv/880+zWLxz5079+eefduePevvtt3X+/HlVq1ZNX3zxhc2cmqldajRx4kQdOXJEYWFh+vjjj23mZHX1EqVOnTqpQoUK+uOPPyRJHTt21COPPKKKFSsqPj5eR48e1bZt2xQZGamtW7e6PDdpckm/FT5//rwGDRqkSpUqyWKxaMSIEal2xLdv364+ffqoSZMmuu+++1SkSBElJCTYvJb8/PzMNnr27KnLly+rRYsWKlq0qAoUKKC//vrL5hKxxC8vko4COXz4sHr27KkqVapo27ZtKUZ8JKpfv76qVatmFiInT56s48ePq0SJEvroo48cXkaYETlPOpfy3r17ZbVanb7kLTWdOnVSuXLlzBH4I0aM0I8//qhChQrpo48+srnEMOn/LQ0aNFCRIkXUtGlTFSlSRIGBgTp48KCZK8n2i6Okr4t9+/bpmWeeUfHixeXn56enn376rs/DWclHAz3wwAPq2LGjjh07Zt4ZOytK62s10fnz5/Xnn39Kuj3iyJ0jpQEgu8rMPpuz/XZHvLy8NGrUKLMIunz5ch07dkwtW7ZUrly5dObMGe3Zs8ecqqpdu3aSpPj4ePXp08e8FLx9+/ZatWqVqlWrplOnTum3337T//73Py1cuNCp80jav/j88881btw4BQcHKzg4WAMHDlSNGjXUqlUrffvtt5Kkl156STt37lTDhg1lsVh09OhRffvttzp37pw5p/+dtGjRQl5eXrJarTp69KguXryYLlM8pPXzniv9Yenu+urpqWzZsmYepduF20cffVSRkZF3nJffkxUqVEidOnUyB968//77unz5sqpVq6bPPvvM/Pt2JCEhwRzkJCnV+6kAHsstt0RDtqd0vMusYRjG/v37jfLly9vcUdLeT+JdRg3j9h0qk96B1d7P4MGDDavVanOsRo0a2d22bdu2No9PnDhh7uPsHeCT7p/0Lp5Jf4KCgow//vjDZr+PP/7YyJEjxx3P31nPPfec3f0rV65sBAcHO7zjaXLJ78z+2muv2d3u119/tdlu4sSJhmGkvKt9x44d7cZVt25d48aNG2Z7ye9Y6mi/Bx980Ob5dfausL///rvNnYgd/SS9s31qr4HU7uYaGRlpcxfYpD/nz59PNe6VK1feMcYxY8aY2ye/K2vynwIFCpiv6+joaKNIkSJ2t0t+N+akfwt79+61udtx4o+/v7/RsmVL83GpUqXuOud3Uq1aNXO/b775JsX6pHewTu3vNrnDhw87zE3iz6RJk2z28ff3T3X7UqVKGf/995+5/c8//2x4eXml2C5XrlxOx5n87yvpXX/trU/6PCbVvn17p14HSdtP7W8tad6T/x/j6O/I0V2673Ss1M4xra9VwzCMRYsWmeu7du1qN28AcK+T0q+/n9b35PTusyWVdP8OHTrY3Pk+8Sd5vz2196v4+HijV69ed4x1wIAB5j4vvviiuTx//vzG6dOnDcMwjC1bttjE8+mnn5r7JP2MkbQtwzCMDRs22D1m5cqVzW3Onj1rVK1a9Y5xJu9XpKZz587mfu+8806K9UljTq2PnlxaPu+50h82DOf66neS/HWRvP+T2usmqSeeeMJuHK1atTKKFi1qt/3UPoek9lpJrX/l6HWQ2rFSO8eTJ08ahQoVSnFeFovFaNeunc3j5L744gtzfc2aNe3mDfB0dz+8CPAANWvW1C+//KLly5era9euKlGihHLkyKHcuXOrQoUKeuihh/TBBx9oyJAh5j5FihTRTz/9pOnTp6t+/foKDAyUj4+PQkND1alTJ23YsEHvvPNOivl2Nm7cqIEDByooKEgBAQGqU6eOPvroI40fPz5dz2ngwIH6/PPP1ahRI+XMmVN58+bVI488oj179qSYkP6RRx7R4cOH9fTTT6tSpUrKlSuXAgICVLp0abVo0ULTpk3TkSNHnD729OnT9dZbb6lSpUry8/NT4cKFNWLECO3YscOlOSuTjrb19va2uQtoUpUqVVK9evXMx46mV5g3b57mz59vxlWkSBGNHj1a3377rc0Nh5Jbu3atJk+erDJlysjPz08lS5bUpEmTtGbNmjTNz1SxYkUdOnRIU6dOVf369ZU3b175+vqqaNGiql+/vv73v/9px44duv/++11uO7lChQpp48aNaty4scvzhTZp0kSvvvqqOnbsqDJlyihPnjzy8fFRSEiIWrVqpYiICM2cOdPcftq0aXriiSdUu3ZtFSpUSL6+vsqZM6cqVqyo4cOHa9++feYdmQsUKKCdO3fq4YcfVmBgoHLkyKG6detq7dq1qc75VadOHe3atUsdO3ZU7ty5lTt3brVq1Urbt29XuXLlzO2Sz2eVETkfOXKk+XvySxrvRpUqVXTo0CG9+OKLqlGjhnLlymXG2r17d23fvl0vvfSSzT6LFi3SoEGDVK1aNYWEhMjHx0e5c+dWtWrVNHbsWP3www/KmzevuX2NGjW0cuVK1apVK9XXfmb45JNPNGrUKBUuXFh+fn4qW7aspk6dmqYR+p4kra9VSfrwww/N3xPvbg0AyHyZ1Wfr0aOHvv76azVt2vSO/XZHvL29tWLFCm3YsEFdunRRkSJF5Ovrq/z586tKlSrq2bOnPvzwQ82dO1eS9P3335uX/ku3+8mJ88W2aNHC5gqcxx57zKkbiT744IOaP3++7rvvvhRzmiYqWLCgfvzxR82bN0/NmjVTgQIF5OPjo0KFCql27dp68skn9dVXX6lPnz5Onbckm1jTs0+Wls97rvSHpbvrq6e3efPmafLkyQoLC5Ovr69KlCih5557Ths3bpSPT9a92DosLEx79uzRo48+qnz58ilHjhxq2LChPv/8c5urmuiT4V5lMYxMmHAFSMZisSgyMtLhjQAiIiL08ccf67PPPsvkyOBJtm3bphYtWpiPT5w4YdNRciQiIkKDBg0yH/PfnOe4efOmfHx8UkxLcPXqVVWpUkV///23pNtTWCxZsiRDY7l165aqVKmio0ePyt/fX8ePH7e5QQayt7S+Vvfu3Wt+EdWyZUvzclIAyG7u9f5+0mLf0qVL3XqzqntBy5YttXXrVkm377NRu3ZtN0cET2G1WhUfH2/e1DdRQkKCGjVqpB9//FGS1KZNG3399dfm+n///VdlypTRzZs3VaFCBf3yyy9ZuoCN7ItXLQAg0/z222968MEH1adPH1WqVEn58+fXyZMntWjRIrMQ5uXllSnfiPv6+mrmzJl68MEHFRcXp9dff90cxQKk9bU6ZcoUc93s2bMzPW4AALKi2bNnq1atWrJarZo8ebJTNwJF9hATE6Ny5cqpd+/eqlGjhkJDQ3X69GlFRESYRVtJKe7zMH36dN28eVOSNHPmTIq2yLJ45cJt7nSX0Y4dO2ZSJAAy0z///KPXXnvN7jo/Pz8tWrRI1atXz5RYOnfuzIhsOJSW12riHacBAPT34bzq1asrISHB3WHAQ124cEFvvvmm3XUWi0WTJk1Sp06dbJa/+eabDvcBshIKt3CL8+fP33Gb5JdCAMj6ihcvrtGjR2vbtm06deqULl++rICAAJUqVUrNmzfX8OHDVbFiRXeHCfBaBYC7RH8fQHrImTOnxo8fr61bt+r48eO6dOmSfH19Vbx4cTVp0kTDhg1T3bp13R0mkGGY4xYAAAAAAAAAPIzXnTcBAAAAAAAAAGQmCrcAAAAAAAAA4GGY49YBq9WqM2fOKE+ePLJYLO4OBwAAAHYYhqErV66oSJEi8vLK3mMS6L8CAAB4Plf6rxRuHThz5oyKFy/u7jAAAADghH/++UfFihVzdxhuRf8VAAAg63Cm/0rh1oE8efJIup3EwMDADD+e1WrV+fPnFRISku1HiyRHbhwjN/aRF8fIjX3kxTFyYx95cSyzcxMTE6PixYubfbfsLLP7rxJ/C46QF8fIjX3kxTFyYx95cYzc2EdeHPPk/iuFWwcSLy8LDAzMtMJtbGysAgMD+QNKhtw4Rm7sIy+OkRv7yItj5MY+8uKYu3LD1ACZ33+V+FtwhLw4Rm7sIy+OkRv7yItj5MY+8uKYJ/dfeaYAAAAAAAAAwMNQuAUAAAAAAAAAD0PhFgAAAAAAAAA8DIVbAAAAAAAAAPAw3JwMAAB4vISEBN26dcvdYZisVqtu3bql2NhYbu6QTHrmxtfXV97e3ukUGQAAyOqc6RPST7OPvDjmyf1XCrcAAMBjGYahs2fP6r///nN3KDYMw5DVatWVK1ecuhtsdpLeucmXL58KFSpEngEAyMZc6RPST7OPvDjmyf1XCrcAAMBjJXbQQ0NDlTNnTo/pZBqGofj4ePn4+HhMTJ4ivXJjGIauX7+uqKgoSVLhwoXTK0QAAJDFuNInpJ9mH3lxzJP7rxRuAQCAR0pISDA76EFBQe4OxwYdX8fSMzc5cuSQJEVFRSk0NJRpEwAAyIZc7RPST7OPvDjmyf1XJrUAAAAeKXH+spw5c7o5ErhT4vPvSXMcAwCAzEOfEFlNevZfKdwCAACPxoiA7I3nHwAASPQJkHWk52uVwq0HSLAa2nM8Wl8fuag9x6OVYDXcHRIAAACQKvqwAAAAGYvCrZt9+Uukmry+Rb3f+VEvfXlCvd/5UU1e36Ivf4l0d2gAACAdWCyWO/5ERESkuf2BAweqSpUq6RJr8+bN1alTp3RpC/c2+rAAALgmq/UJE2Py8vJSiRIl1KdPH/3999/p0r6zIiIiZLFYdOHChXRvO3m/97vvvtPUqVPT/Th3i5uTudGXv0TqyQ/2K/nYhLOXY/XkB/u1qG8tta/CHZQBAMjKdu/ebfO4YcOGGjlypHr37m0uK1OmTJrbf/HFF3Xt2rU07w+4ij4sAACuy2p9wsaNG2vmzJlKSEjQ4cOHNXHiRO3Zs0eHDx++J+YbXrhwoc2Nw7777jvNnj1bEyZMcGNUKVG4dZMEq6FJG39L0eGVJEOSRdKkjb+pTaVC8vZiHhcAAO5WgtXQjycuKupKrELzBKheqQKZ8h7boEGDFMtKlChhd3mi2NhYBQQEONX+3XTwAVfRhwUA3Avc0S/Man3CfPnymbE1btxYuXLlUv/+/bVp0yZ169YtTW0ahqGbN2/K398/PUNNk0qVKrk7BKcwVYKb/HjioiIvxzpcb0iKvByrH09czLygAAC4RyVe1t3r7T16ZtUB9Xp7j8dc1h0eHq7cuXPrxx9/VMOGDRUQEKB58+ZJksaNG6eqVasqd+7cKlq0qHr16qXISNuYk18Wl3hJ2f79+9WhQwflypVL5cqV07Jly9Il3vXr16tmzZoKCAhQoUKFNGLECF29etVcf+vWLY0bN04lS5aUv7+/ChcurM6dO+vy5cvm+ueee05hYWF218Oz0YcFAGR1ntovzOg+Ye7cuVWpUqU09wlr164tSTpx4oQkKS4uTi+88ILZp7vvvvu0YsUKuzFt2rRJ1atXl7+/vz799FNt27ZNFotFmzZt0sMPP6xcuXKpcOHCTk1VcKfj/vTTT/L19dX8+fPNZbdu3VLNmjXVsGFDJSQkSLKdKiE8PFyvvPKKrl27Zk4R0bx5cx06dEgWi0XffPONTQxWq1UlSpTQmDFj0pBJ11C4dZOoK447vGnZDgAA2Jd4WXfyYlPiZd3u7qRL0s2bN9WnTx/169dPX375pdq2bStJioqK0gsvvKDPP/9cc+fO1cmTJ9WsWTPFx8ffsc2+ffuqbdu2Wr9+vapXr66BAwfqt99+u6s4P/30Uz388MMqX7681q1bpxdffFHLly/XQw89ZG4zbdo0LVmyRGPHjtXXX3+t+fPnq0iRIoqLizPXv/XWW3r++eftrodnow8LAMjKPL1fmJF9wnXr1qlq1aoaNGhQmvqEiQXbIkWKSJJ69OihxYsX63//+58+++wztW/fXn379tUXX3xhs9+ZM2f0zDPPaMyYMfryyy9Vo0YNc93jjz+uMmXKaO3aterbt68mTJigt956K9U47nTcOnXqaOLEiRo7dqz++OMPSdLLL7+sY8eOafny5TbTIyQaMmSIBg0apBw5cmj37t3avXu3Fi5cqGrVqql+/fp69913bbb/+uuv9c8//2jw4MGuJTENmCrBTULzODfU3dntAABASlnlsu5bt25p6tSp6t69u83y9957z/w9ISFBDRs2VLFixbRlyxazI+/IU089peHDh0u6fWne559/rrVr197VZWHh4eGqW7euVq9ebS4rUKCAevfurW3btql58+bau3evWrdureHDh8tiuZ3TRx55xNz+xx9/VNu2bc3Ykq+HZ6MPCwDIqrJCvzAj+4SGYahOnTr64osvnOoTGoah+Ph4Wa1WHT58WGPHjlW+fPnUunVrbd26VZ9++qm++uor8/ht2rTR6dOn9fLLL6tDhw5mO5cuXdKXX36pevXqmctOnz4tSWrZsqVmzJghSWrXrp3Onj2rV199VY8//ri8vFKONXX2uBMmTNDnn3+ufv36aebMmZo+fbrmz5+vsmXL2j3XYsWKqWjRovLy8koxdcXQoUP11FNP6dKlS8qfP7+k289H/fr1Vbly5VRzmB4o3LpJvVIFVDhvgM5ejrX7n4ZFUqG8t+dZAQAA/1/neTt1/opzozPj4hN06foth+sTL+uu88pm+fuk/PbdkZA8flr7hOP5yNLigQceSLHsiy++0JQpU/Trr78qJibGXH706NE7dtKTrs+TJ4+KFy+uf//9N83xXb16VQcOHDA714m6d++u/v37a8eOHWrevLlq1qypmTNnKjw8XJ06dVLt2rVtOt61atXSjBkzFB4ero4dO6ZYD89GHxYA4ClS6xMaMmSRbfE1I/qFIXn8tXFkE6djdoan9Ak3bdokX19f83H58uW1du1aFSxYUHPmzFGBAgXUsmVLm1G/rVq10lNPPaWEhARzZGtwcLBN0Taprl272jx++OGH9cEHH+jff/9ViRIlUmz/9ddfO3VcHx8fLV++XDVr1lTbtm3Vtm1bPfHEE3c8Z3seffRRjR49WitWrNCIESMUHR2tTz/91JzGIqNRuHUTby+LXu5cSU9+sF8Wyabjm/hfy8udK3FTBwAAkjl/JU5nY9L3MuzbnXjHHfmMljNnTuXKlctm2d69e/Xggw+qS5cuGjdunEJDQ2WxWNSgQQPFxt75/PPly2fz2M/Pz6n9HPnvv/9kGIYKFSpks9zHx0dBQUG6ePH2nKaJd+JdtmyZJk+erJCQEI0YMUIvvfSSLBaLJkyYIC8vL73//vuaNGlSivXwbEn7sMnRhwUAZKaM6BNK7u0XelKfsEmTJpo9e7a8vb1VtGhRhYaGmusuXLigixcv2hR2k4qMjFSxYsUkyWa/5JKvS3wcGRlpt3DrynErVKigOnXqaMeOHXrqqadSOdPU5cqVS7169dK7776rESNG6IMPPpCPj48effTRNLfpCo8o3C5cuFAzZsxQZGSkKleurDlz5qhp06Z2t925c6eef/55HTlyRNevX1dYWJiGDRum0aNHm9tERERo0KBBKfa9ceOG03fjywztqxTWor61NGnjbzbzqxTKG6CXO1dS+yqF3RgdAACeKSSP83ehvdPIikT5c/q6POI2PdkrWK5bt0558+bVRx99ZI5I/fvvv9P1uK7Ily+fLBaLzp07Z7M8Pj5e0dHRKlDg9ghLf39/vfTSS5o8ebL++usvvffeewoPD1fp0qXVr18/+fv7Kzw8XOHh4frzzz9TrIfnS+zDjljxsxKs/3/4AX1YAEBmSq1PmJYRt4lc6Re60i91hif1CfPmzas6derYXVegQAGFhIRo06ZNdtcnLcim9sV8VFSU3ceFC9vvS7hy3Lffflu7du1StWrVNGbMGLVo0UI5cuRwGEtqhg4dqiVLlujAgQNaunSpunfvrjx58qSpLVe5vXC7evVqjRo1SgsXLlTjxo21ePFidejQQb/99pvd6nquXLn01FNPqVq1asqVK5d27typYcOGKVeuXHr88cfN7QIDA81JiBN5UtE2UfsqhdWmUiHVnrJZ/924paBcvtr5fEtGKQAA4IArl6MlWA01eX3LHS/rdvW9N3HOr4x048YN+fr62nR2P/zwwww9Zmpy586tGjVq6KOPPrK5g+4nn3yi+Ph4u1+6ly1bVlOnTtXixYv1+++/u7wenqt9lcIqGfSH/jp/Tf7eFi0dVFf1SwfThwUAZBpHfcLEfpqPj49NPyqj+oUZzdP6hJLUunVrTZ8+XX5+fqpWrVqa21m3bp3NdAlr165VkSJFzFGzaT3u8ePHNWbMGI0dO1ZPPvmkqlatqueff15vvvmmw338/Pwc3iy3Tp06qlGjhp555hkdPHhQ8+fPd/IM757bC7ezZs3S4MGDNWTIEEnSnDlz9NVXX2nRokWaNm1aiu1r1qypmjVrmo9LliyptWvXaseOHTaFW4vFkuJSPk/l7WWRn8/tb038fb096j8IAACysqw8NVGbNm00Z84cjRw5Ul27dtXu3bu1fPnyDD/u2bNn9fHHH6dY/sADDyg8PFwPPfSQevXqpQEDBuj48eMaP368WrVqpebNm0u6PVdZjRo1VLt2beXOnVsbN27UxYsX1bJlS0nSQw89pNq1a6tmzZrKlStXivXIOhI/QPp4W9SgdJC8PPDvCACARFm1X+iuPuGdYurcubPat2+vsWPHqlq1arp27Zp+/fVX/fnnn3rnnXecamfLli167rnn1KZNG23evFkffPCBFixY4PD+B84c12q1asCAASpTpozCw8Pl5+enefPmacCAAXrwwQfVunVru21XrFhR8fHxmjt3rho1aqTAwEBVqFDBXD906FCNGDFC5cuXV5Mm6TuvcWrcWri9efOm9u3bp3Hjxtksb9u2rXbt2uVUGz///LN27dqlV155xWb51atXFRYWpoSEBNWoUUNTpkyxKfgmFxcXZ1NZT5zs2Wq1ymq1OntKd89Q5h4vC7BarTIMg7zYQW7sIy+OkRv7yItj7sxN4rETf9KqXeVCWtinliZ99pvOJpua6KVOldSucqE0tZ+4T1r3Tb5/8nY6dOig1157TfPnz9fSpUvVuHFjbdy4URUqVLCbE3vt2YvtTvHu27cvxZ2MpdsjFzp37qyPP/5YU6ZMUZcuXZQvXz716dNHr7/+utluo0aN9NFHH2nOnDmKj49XhQoV9OGHH6pVq1YyDEONGjXSmjVr9MYbb9hd7yhXjvpk/N0CAABnZcUpKx944AG9/vrrmjdvntkn/Oyzz1S+fHm3xvXxxx/rtdde08KFC/X3338rb968qlKlit2pSx1ZvHixFi9erIULFypPnjyaMmWKhg8fflfHnT59un788Uft3btXfn63pzfr16+fNmzYoEGDBunw4cMp5v2VpE6dOunJJ5/UtGnTFBUVpfvvv1/btm0z13ft2lUjRozQ4MGDnT6/9GAx7uaT0F06c+aMihYtqu+//16NGjUyl0+dOlXvv/9+iqkOkipWrJjOnz+v+Ph4hYeH68UXXzTX7dmzR3/++aeqVq2qmJgYzZ07V5s2bdLBgwdVrlw5u+2Fh4dr0qRJKZYfPXo0U+at6PT2QV24Fq+CeXy1YXDah5nfi6xWqy5fvqy8efNy1+lkyI195MUxcmMfeXHMnbm5deuWLl++rLCwsHSZ7ijBauinvy8p6kqcQvP4q05Y/jSPqDAMw7xrLTfUspXeuYmNjTU75fZuRHHlyhWVL19ely9fVmBg4F0fLyuLiYlR3rx5My0XrWd9pz+jriqXn5cOh7fj/88krFaroqKiFBoaSl6SITf2kRfHyI192SkvsbGxOnHihEqVKuVUn9DRVAlJJVgN/XjioqKuxCo0T4DqlSrgcSNt05szecks27ZtU4sWLbR3716H8+hmJmdy895772nYsGH6559/7niF/51es6702dw+VYKUcqJiwzDu+CLasWOHrl69qj179mjcuHEqW7asevXqJUlq0KCBGjRoYG7buHFj1apVS/PmzXM4n8X48eNt5muLiYlR8eLFFRISkikdXy8vb0nx8vbyTvWOe9mR1WqVxWJRSEjIPf+G5CpyYx95cYzc2EdeHHNnbmJjY3XlyhX5+PjIx+fuuyw+khqXS9/3WEd3tEX65cbHx0deXl4KCgqy2/H1xHsYAAAAz+btZVHDMkHuDgNZwMmTJ3Xs2DFNmTJFPXv2zPRpWd1auA0ODpa3t7fOnj1rszwqKkoFCxZMdd9SpUpJkqpWrapz584pPDzcLNwm5+Xlpbp16+rYsWMO2/P395e/f8q7AXp5eWXuB1WLKBrYYbFYMv+5yCLIjX3kxTFyYx95ccxdufHy8pLFYjF/PEnSL5k9LTZ3S+/cJD7/jl6D/M0CAAAgo4SHh2vFihVq1KiR3njjjUw/vlt7un5+fqpdu7Y2b95ss3zz5s02UyfciWEYDu/8lrj+wIEDKlzY8+YqAQAAAAAAALKL5s2byzAMj5gm4U4iIiJ08+ZNbdu27Y6DTDOC26dKGDNmjPr166c6deqoYcOGWrJkiU6dOqUnnnhC0u0pDE6fPq1ly5ZJkhYsWKASJUqoYsWKkqSdO3dq5syZGjlypNnmpEmT1KBBA5UrV04xMTF68803deDAAS1YsCDzTxAAAAAAAAAAXOT2wm3Pnj0VHR2tyZMnKzIyUlWqVNGmTZsUFhYmSYqMjNSpU6fM7a1Wq8aPH68TJ07Ix8dHZcqU0WuvvaZhw4aZ2/z33396/PHHdfbsWeXNm1c1a9bU9u3bVa9evUw/PwAAAAAAAABwldsLt5I0fPhwDR8+3O66iIgIm8cjR460GV1rz+zZszV79uz0Cg8AAAAAAAAAMhV3cwAAAAAAAAAAD0PhFgAAAAAAAAA8DIVbAAAAAAAAAPAwFG4BAAAAAAAAwMNQuAUAAMhAnTt3Vrly5RyuX7RokSwWi44ePepUe82bN1enTp1S3SY8PFy5c+d2KU4AAABkHHf1CS0WiywWi7y8vFSkSBG1bt1aO3bscCn2u3Xy5ElZLBZ9/PHH6d528n7vyZMnFR4erjNnzqT7sdyBwi0AALi3/fePdOaA45///snQw/fp00d//vmn9u7da3f9ihUrVKdOHZUvXz5D4wAAAMj23NgvdFefMEeOHNq9e7d27dqlefPmKTo6Wq1atdLhw4fT9TjuMmTIEG3dutV8fPLkSU2aNOmeKdz6uDsAAACADPPfP9L82lJ8nONtfPylp/ZJ+YpnSAgPPvigcufOrRUrVqhu3bo2606dOqXvv/9es2bNypBjAwAA4P+4uV/orj6hl5eXGjRoIMMwVKdOHTVs2FClSpXS4sWLNX/+/DS3e+PGDeXIkSMdI02bYsWKqVixYu4OI8Mw4hYAANy7rken3jmXbq+/Hp1hIeTMmVMPPfSQVq9eLavVarNu5cqVslgs6tmzp65du6annnpKFSpUUM6cOVWyZEk98cQTunz5cobE9csvv6h9+/bKnTu3AgMD1aVLF/35558227z33nuqXLmycuTIoaCgIDVp0sRmlMid1mdn27dvV+fOnVWkSBFZLBatX7/e6X2///57+fj4qEaNGhkWHwAA2Y6b+4We0icsUaKEgoODdeLECXNZRESEqlWrpoCAABUtWlQTJkxQfHy8zXqLxaLdu3erTZs2ypUrl5599llJksVi0WuvvaaxY8cqJCREefLk0cCBA3XlypU7xpLacWNiYhQWFqbu3bvb7DNixAjlz59f//77ryTbqRK2bdumFi1aSJLq1q1rThNx69YtFSpUSBMnTkwRQ+/evVW7dm1XUpipKNwCAABksD59+igyMlLbtm2zWb5ixQq1bNlShQsX1vXr15WQkKBXX31VX3zxhV555RV999136tq1a7rH888//6hp06Y6d+6c3n//fb3zzjs6evSomjZtqvPnz0u6XXgcPHiwHnjgAW3atEnLli1Tq1at9N9//zm1Pru7du2aqlev7vJIlsuXL6t///5q1apVBkUGAADcxRP6hDExMbp48aKKFCkiSZo1a5aGDBmidu3aaePGjXr++ef15ptv2i1y9unTR61atdJnn32mfv36mcvnzZun33//Xe+//75ee+01ffLJJxo6dGiqcdzpuIGBgYqIiNAnn3yi5cuXS5K++uorLVy4UAsXLrQ7yrZWrVpasGCBJGnp0qXavXu3du/eLV9fXw0cOFARERE2RfP//vtP69at02OPPeZiFjMPUyUAAICsZXEz6WqUc9sm3HRuuw8ekbz9nI8hd6j02DdOb966dWuFhoZq5cqVatmypSTp999/16FDh7R06VJJUkhIiBYtWmTuEx8fr1KlSqlJkyY6evRous53Nnv2bN28eVNff/21QkJCJEn169dXuXLltGDBAoWHh+vHH39UgQIFNGPGDHO/jh07mr87Wm8Yhs0IjeyqQ4cO6tChg8v7DRs2TL1795a3t7dLo3QBAMh2UukT+siQZLFdmBH9wtyh0rDvnNtW7usTxsfHyzAMnTx5UuPGjVNCQoK6deumK1eu6OWXX9bYsWM1depUSVKbNm3k4+OjZ599Vs8995yCgoLMdp588kk999xzKdr39/fX+vXr5e3tLUkKCAjQ0KFDFR4erooVK6bY3tnjtmjRQqNGjdLIkSNVtWpVPfbYY+rZs6d69epl9zwDAwNVqVIlSVKVKlVUp04dc92QIUM0ffp0ffXVV2YfbcWKFZJuj7r1VBRuAQBA1nI1SrqSzjcbuH4hfdtLxsfHRz169NCHH36oBQsWyM/PTx9++KECAgL08MMPm9stX75cs2bN0rFjx3Tt2jVzeXoXbnfs2KGWLVuaRVtJCgsLU6NGjcy7DNeqVUsXL17UwIED1adPHzVu3Fg5c+Y0t7/Terhu6dKl+uuvv/TBBx/olVdeueP2cXFxiov7/5d8xsTESJKsVmuKSzAzhGGYv2bK8bIQq9UqwzDIix3kxj7y4hi5sS875SXxXBN/TFejZLHTJ7SkWOIiF/qFhmTzfngn3t7e6t69u1asWKH58+fLz89PH3zwgQICAtS1a1fz/JYvX67Zs2en6BP+8ccfKleunG0MqRzfMAxdu3ZNvr6+5rL8+fNr3rx5atu2rb766itdvXpV3bp1061bt8xtWrRooRs3bujw4cNq1qyZeYwOHTrYPV6nTp3k5eVlruvatauGDBmiH374QRUqVDCXJz6H33//vVPHlaRXX31VX331lRo0aKCgoCAtXLjQJoakbSf/N+l2ZcqUUfPmzfXee++pffv2km5P+/Xwww8rf/78Zhyp5dNZicd21Cdz5e+Wwi0AAMhacoc6v23CTec63zmDXR9x66I+ffpo/vz5+vLLL/Xggw9q5cqV6tSpkwIDAyVJ69atU//+/fX444/r1VdfVVBQkCIjI9W1a1fFxsa6fLzUXLp0ye78qYUKFdIff/whSWrZsqWWL1+uuXPnql27dgoICFC3bt00Z84cFShQwOH62bNnm+cE5x07dkzjxo3Tjh075OPjXBd92rRpmjRpUorl58+fT/fXjD3xCQmSbn84iYqKkpcXs7Alslqtunz5sgzDIC/JkBv7yItj5Ma+7JSXW7duyWq1Kj4+3uaqHu9cIfq/0mlKdgbcKuGWLE70C42cwZK37x23kyQjV4gSXLzS6NFHH9WCBQv0+eefq3Pnzlq1apUeeOAB5cyZU/Hx8Vq/fr0GDBigIUOGaNKkSWafsHv37rp27ZqZg8TiYGpXOlmtVuXIkUNbtmyRdLtoGxYWJm9vb8XHx+vcuXOS5HCO15MnT6px48ZmobFAgQJ2jxccHGyzPE+ePPL19dXp06dtnreEhASXjivdHgDRpUsXTZs2TY8++qjy5Mljc6zE2JIeI+mxkho0aJCGDBmis2fP6syZM9q3b5+mTp2qW7dumftZLHdd+ld8fLysVquio6NtiuaJnJn/NxGFWwAAkLW4cDmazhyQljS783Z9P5GK1HC+XcOQXOykN2jQQKVLl9bKlSsVGhqq48eP64033jDXr1mzRjVq1NDixYvNZd9958K5uqBAgQJmhzmps2fPqkCBAubjvn37qm/fvrpw4YI2bNig0aNHy9fXV++++67D9T4+PjbngDtLSEhQ7969NWnSJJdGVo8fP15jxowxH8fExKh48eIKCQnJlOK5j/cRSbc/4ISGht7zhQNXWK1WWSwWhYSEkJdkyI195MUxcmNfdspLbGysrly5Ih8fH9svN1PpE966dStlwSzygLSk+Z0P2PdjqXANp2KzyPXCWuPGjVW6dGmtWbNGhQsX1vHjxzVz5kzz3NatW6caNWpoyZIl5j6JfUJvb29zu8Qbb6X2ha+Xl5e8vLxUv359SSnzknj11SeffKLixYun2L9UqVLy8fExX2O+vr52j3fhwgWb5ZcuXdKtW7dUtGhRm+ctMX5njyvdvqHurFmzVLNmTS1cuFCPPfaYOR1C4jlKsjlG8lwl6t69u0aPHq1Vq1bpxIkTKlWqlFq3bm0Wa+0VWdMiMWdBQUEKCAhIsd7eModtpUtEAAAAuKPevXtr1qxZypkzp/Lly6cHHnjAXHfjxg35+dmO+v3www8zJI4mTZpo8eLFio6ONuct++eff7Rr1y698MILKbYPDg7W4MGDtWnTJv3++++prj9y5EiGxHwvu3Llin766Sf9/PPPeuqppyT9/8tCfXx89PXXX5vz4CXl7+8vf3//FMsTP6RluCQjUjLtmFmIxWIhLw6QG/vIi2Pkxr7skhcvLy+zSOnMaEjDMMztbLd3biSlRRab97iMkLxP2LFjRzPWxD5h0tgT52K1l4PUcpI0D/bykjjV1enTp22m70qtHXvH++yzzzR79myzaLpu3TpZLBbVq1fPZp/E35097s2bN9W/f3/VqVNHW7ZsUZMmTdS/f3/t2bPHLLImP6fEvlFcXFyKWAMCAtSvXz+98847OnfunEaNGmVO8WD/NZM2iefp6O/Tlb9ZCrcAAODelTNI8vGX4uMcb+Pjf3u7TNCnTx+98sorWrp0qQYPHmxTqG3Tpo1GjBihyZMnq1GjRvriiy/07bffpvlYCQkJ+vjjj1Msr1u3rkaPHq2lS5eqbdu2mjBhghISEvTyyy+rQIECGjFihCTp5ZdfVnR0tJo3b67Q0FAdPnxYX375pTnC09H60aNHpznm7CowMFCHDx+2WbZw4UJt2bJFH3/8sUqVKuWmyAAAuId4UL8wM/uEqcmbN68mT56ssWPH6t9//1WLFi3k5eWl48ePa8OGDfrkk0+cuodBXFycHnroIQ0fPlwnTpzQ888/r27duum+++67q+O+/PLLOnbsmA4ePCg/Pz8tX75cNWvW1OTJkzVlyhS7bZcvX17e3t5677335O3tLV9fX5ublA0dOlRz5syRl5eXBg4cmKa8ZSYKtwAA4N6Vr7j01D7perTjbXIG3d4uE1SsWFG1atXS/v37U9y9dtiwYTp+/Ljmz5+vmTNnql27dlqxYoUaNGiQpmPFxsaqe/fuKZYvXbpUAwcO1Pbt2/Xss8+qX79+8vLyUosWLfTGG2+Yl67VrVtXc+bM0UcffaSYmBgVK1ZMzz33nCZOnJjq+gkTJqQp3nvN1atX9eeff5qPT5w4oQMHDqhAgQIqUaKExo8fr9OnT2vZsmXy8vJSlSpVbPYPDQ1VQEBAiuUAACCNPKhfmJl9wjv53//+p6JFi2rWrFmaN2+efH19VaZMGXXq1CnF1WCOjBw5UufPn1ffvn118+ZNde3aVfPnz7+r4+7atUvTp0/XwoULVaZMGUlShQoVNH36dI0aNUqdOnUyp4BIKjg4WAsWLND06dO1fPlyxcfH29xwrFKlSipfvrzKlCmjYsWKuZAp97AY6XG7tHtQTEyM8ubNq8uXL2fKHGH1Xv1GUVfiVCRfgHaNa5Xhx8tKrFaroqKimDvNDnJjH3lxjNzYR14cc2duYmNjzbmnXJkHKjMk3gjCx8cnXS6nupekd27u9DrI7D6bs7Zt26YWLVqkWD5gwABFRERo4MCBOnnypLZt22Z3//DwcK1fv14HDhxw+piZnYvWs77Tn1FXlcvPS4fD2/H/ZxK8rzhGbuwjL46RG/uyU15c7RPST7Mvo/JisVg0Y8YMPfvss+nWZkb666+/VK5cOa1Zs0aPPPKIJM/uvzLiFgAAAEhnzZs3V2rjIyIiIlLdPzw8XOHh4ekbFAAAQDYVHR2to0ePatKkSQoLC1OXLl3cHZJT7u2vZQAAAAAAAABkaxs3blTjxo114sQJffDBB/LxyRpjWbNGlAAAAAAAAAA8SlaZgXXgwIFZ4mZkyTHiFgAAAAAAAAA8DIVbAAAAAAAAAPAwFG4BAIBHyyqXXyFj8PwDAACJPgGyjvR8rVK4BQAAHsnX11eSdP36dTdHAndKfP4TXw8AACB7oU+IrCY9+6/cnAwAAHgkb29v5cuXT1FRUZKknDlzymKxuDmq2wzDUHx8vHx8fDwmJk+RXrkxDEPXr19XVFSU8uXLJ29v73SMEgAAZBWu9gnpp9lHXhzz5P4rhVsAAOCxChUqJElmR91TGIYhq9UqLy8vOr7JpHdu8uXLZ74OAABA9uRKn5B+mn3kxTFP7r9SuAUAAB7LYrGocOHCCg0N1a1bt9wdjslqtSo6OlpBQUHy8mLmqaTSMze+vr6MtAUAAC71Cemn2UdeHPPk/iuFWwAA4PG8vb09qoBntVrl6+urgIAAOr7JkBsAAJBRnOkT0hexj7w45sm58axoAAAAAAAAAAAUbgEAAAAAAADA01C4BQAAAAAAAAAPQ+EWAAAAAAAAADwMhVsAAAAAAAAA8DAUbgEAAAAAAADAw1C4BQAAAAAAAAAPQ+EWAAAAAAAAADwMhVsAAAAAAAAA8DAUbgEAAAAAAADAw1C4BQAAAAAAAAAPQ+EWAAAAAAAAADwMhVsAAAAAAAAA8DAeUbhduHChSpUqpYCAANWuXVs7duxwuO3OnTvVuHFjBQUFKUeOHKpYsaJmz56dYrtPPvlElSpVkr+/vypVqqR169Zl5CkAAAAAAAAAQLpxe+F29erVGjVqlCZMmKCff/5ZTZs2VYcOHXTq1Cm72+fKlUtPPfWUtm/frt9//10TJ07UxIkTtWTJEnOb3bt3q2fPnurXr58OHjyofv36qUePHvrhhx8y67QAAAAAAAAAIM3cXridNWuWBg8erCFDhui+++7TnDlzVLx4cS1atMju9jVr1lSvXr1UuXJllSxZUn379lW7du1sRunOmTNHbdq00fjx41WxYkWNHz9erVq10pw5czLprAAAAAAAAAAg7dxauL1586b27duntm3b2ixv27atdu3a5VQbP//8s3bt2qVmzZqZy3bv3p2izXbt2jndJgAAAAAAAAC4k487D37hwgUlJCSoYMGCNssLFiyos2fPprpvsWLFdP78ecXHxys8PFxDhgwx1509e9blNuPi4hQXF2c+jomJkSRZrVZZrVanz+muGcrc42UBVqtVhmGQFzvIjX3kxTFyYx95cYzc2EdeHMvs3PAcAAAA4F7l1sJtIovFYvPYMIwUy5LbsWOHrl69qj179mjcuHEqW7asevXqleY2p02bpkmTJqVYfv78ecXGxjpzGnfFak2QJCVYExQVFZXhx8tKrFarLl++LMMw5OXl9tk9PAq5sY+8OEZu7CMvjpEb+8iLY5mdmytXrmT4MQAAAAB3cGvhNjg4WN7e3ilGwkZFRaUYMZtcqVKlJElVq1bVuXPnFB4ebhZuCxUq5HKb48eP15gxY8zHMTExKl68uEJCQhQYGOjSeaWFl5e3pHh5e3krNDQ0w4+XlVitVlksFoWEhPDhOBlyYx95cYzc2EdeHCM39pEXxzI7NwEBARl+DAAAAMAd3Fq49fPzU+3atbV582Z17drVXL5582Z16dLF6XYMw7CZ5qBhw4bavHmzRo8ebS77+uuv1ahRI4dt+Pv7y9/fP8VyLy+vzP1AZhEfAO2wWCyZ/1xkEeTGPvLiGLmxj7w4Rm7sIy+OZWZuyD8AAADuVW6fKmHMmDHq16+f6tSpo4YNG2rJkiU6deqUnnjiCUm3R8KePn1ay5YtkyQtWLBAJUqUUMWKFSVJO3fu1MyZMzVy5EizzWeeeUb333+/Xn/9dXXp0kUbNmzQN998o507d2b+CQIAAAAAAACAi9xeuO3Zs6eio6M1efJkRUZGqkqVKtq0aZPCwsIkSZGRkTp16pS5vdVq1fjx43XixAn5+PioTJkyeu211zRs2DBzm0aNGmnVqlWaOHGiXnzxRZUpU0arV69W/fr1M/38AAAAAAAAAMBVbi/cStLw4cM1fPhwu+siIiJsHo8cOdJmdK0j3bp1U7du3dIjPAAAAAAAAADIVEwKBgAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAehsItAAAAAAAAAHgYCrcAAAAAAAAA4GEo3AIAAAAAAACAh6FwCwAAAAAAAAAexuXC7ZkzZ/THH3+YjxMSEjR9+nQ9+uijeu+999I1OAAAAAAAAADIjnxc3WHYsGEqUaKEFixYIEmaMmWKJk+erHz58mnNmjXy8/NT37590z1QAAAAAAAAAMguXB5xu3//frVo0cJ8/Pbbb2v06NG6ePGiHn/8cbOgCwAAAAAAAABIG5cLt9HR0SpUqJAk6ffff1dkZKQGDhwoSXrkkUdsplEAAAAAAAAAALjO5cJt3rx5FRUVJUnavn27ChQooKpVq0qSLBaLbt68mb4RAgAAAFnM9u3b1blzZxUpUkQWi0Xr169PdfudO3eqcePGCgoKUo4cOVSxYkXNnj07c4IFAACAR3K5cFuvXj29/vrr2rhxo+bOnau2bdua644fP64iRYq4HMTChQtVqlQpBQQEqHbt2tqxY4fDbdeuXas2bdooJCREgYGBatiwob766iubbSIiImSxWFL8xMbGuhwbAAAA4Kpr166pevXqmj9/vlPb58qVS0899ZS2b9+u33//XRMnTtTEiRO1ZMmSDI4UAAAAnsrlm5NNmTJFbdq0UZcuXZQ/f35NmDDBXLd+/XrVq1fPpfZWr16tUaNGaeHChWrcuLEWL16sDh066LffflOJEiVSbL99+3a1adNGU6dOVb58+bR06VJ17txZP/zwg2rWrGluFxgYmGLahoCAABfPFgAAAHBdhw4d1KFDB6e3r1mzpk1ftmTJklq7dq127Nihxx9/PCNCBAAAgIdzuXBbo0YN/f333zpy5IjKli2rwMBAc93w4cNVrlw5l9qbNWuWBg8erCFDhkiS5syZo6+++kqLFi3StGnTUmw/Z84cm8dTp07Vhg0btHHjRpvOrsViMefiBQAAALKSn3/+Wbt27dIrr7zi7lAAAADgJi4XbiUpZ86cqlWrVorlHTt2dKmdmzdvat++fRo3bpzN8rZt22rXrl1OtWG1WnXlyhUVKFDAZvnVq1cVFhamhIQE1ahRQ1OmTLEp7CYXFxenuLg483FMTIzZvtVqdfaU7p6hzD1eFmC1WmUYBnmxg9zYR14cIzf2kRfHyI195MWxzM7NvfYcFCtWTOfPn1d8fLzCw8PNwQ32uL3/ahjmr/fa83C3+D/CMXJjH3lxjNzYR14cIzf2kRfHPLn/6nLhdsuWLYqOjlb37t0lSefOndOgQYO0f/9+tW3bVkuWLHF6SoILFy4oISFBBQsWtFlesGBBnT171qk23njjDV27dk09evQwl1WsWFERERGqWrWqYmJiNHfuXDVu3FgHDx50OCJ42rRpmjRpUorl58+fz5S5ca3WBElSgjXBvPkbbrNarbp8+bIMw5CXl8vTMt/TyI195MUxcmMfeXGM3NhHXhzL7NxcuXIlw4+RmXbs2KGrV69qz549GjdunMqWLatevXrZ3dbd/df4hNv9V8MwFBUVxd9CEvwf4Ri5sY+8OEZu7CMvjpEb+8iLY57cf3W5cPvSSy+pTZs25uOxY8dqx44datOmjT7++GOVK1dOL774okttWiwWm8eGYaRYZs/KlSsVHh6uDRs2KDQ01FzeoEEDNWjQwHzcuHFj1apVS/PmzdObb75pt63x48drzJgx5uOYmBgVL17cvAlaRvPy8pYUL28vb5tzwe0/IIvFopCQEP5zSYbc2EdeHCM39pEXx8iNfeTFsczOzb12D4NSpUpJkqpWrapz584pPDzcYeHW3f1XH+8jkm735UNDQ/lbSIL/IxwjN/aRF8fIjX3kxTFyYx95ccyT+68uF26PHj2q559/XpIUHx+vdevW6fXXX9fw4cM1c+ZMvffee04XboODg+Xt7Z1idG1UVFSKUbjJrV69WoMHD9aaNWvUunXrVLf18vJS3bp1dezYMYfb+Pv7y9/f3+6+mfqCtog/IDssFkvmPxdZBLmxj7w4Rm7sIy+OkRv7yItjmZmbezn/hmHYTIWQnNv7r0kGWvC3kBL/RzhGbuwjL46RG/vIi2Pkxj7y4pin9l9djiYmJkb58uWTJO3bt0/Xrl3Tgw8+KEmqV6+eTp065XRbfn5+ql27tjZv3myzfPPmzWrUqJHD/VauXKmBAwdqxYoVTs2raxiGDhw4oMKFCzsdGwAAAJBWV69e1YEDB3TgwAFJ0okTJ3TgwAGzrzx+/Hj179/f3H7BggXauHGjjh07pmPHjmnp0qWaOXOm+vbt647wAQAA4AFcHnEbGhqqY8eOqWnTpvrmm28UFhamYsWKSbo9R4Ovr69L7Y0ZM0b9+vVTnTp11LBhQy1ZskSnTp3SE088Iel2p/b06dNatmyZpNtF2/79+2vu3Llq0KCBOVo3R44cyps3ryRp0qRJatCggcqVK6eYmBi9+eabOnDggBYsWODq6QIAAAAu++mnn9SiRQvzceKUBgMGDFBERIQiIyNtBjxYrVaNHz9eJ06ckI+Pj8qUKaPXXntNw4YNy/TYAQAA4BlcLty2b99eL7zwgn799VdFRERowIAB5rojR46oZMmSLrXXs2dPRUdHa/LkyYqMjFSVKlW0adMmhYWFSVKKTu3ixYsVHx+vESNGaMSIEebyxE6wJP333396/PHHdfbsWeXNm1c1a9bU9u3bVa9ePVdPFwAAAHBZ8+bNZRiGw/WJ/dZEI0eO1MiRIzM4KgAAAGQlLhdup06dqlOnTuntt99WvXr1NHHiRHPdihUrUp3iwJHhw4dr+PDhdtcl79Ru27btju3Nnj1bs2fPdjkOAAAAAAAAAPAELhdug4OD9eWXX9pdt3Xr1nvuzr4AAAAAAAAAkNnu6lZpsbGxioyMVGxsrCQpMDBQfn5+6RIYAAAAAAAAAGRXaSrc7tq1S02bNlWePHlUrFgx5cmTR82aNdPu3bvTOz4AAAAAAAAAyHZcniphz549atmypfLly6fHH39cRYoU0enTp7V27Vq1bNlS27ZtU/369TMiVgAAAAAAAADIFlwu3L700kuqVq2atm7dqly5cpnLZ8yYoRYtWuill17SV199la5BAgAAAAAAAEB24vJUCXv27NHYsWNtiraSlCtXLj333HNMlwAAAAAAAAAAd8nlwm1CQoL8/f3trgsICFBCQsJdBwUAAAAAAAAA2ZnLhdvq1atr0aJFdtctXrxY1atXv+ugAAAAAAAAACA7c3mO23Hjxumhhx5SzZo11bdvXxUuXFiRkZFasWKFDhw4oPXr12dAmAAAAAAAAACQfbhcuH3wwQf1wQcfaOzYsXruuefM5UWLFtUHH3ygzp07p2uAAAAAAAAAAJDduFy4laTevXurV69e+uOPPxQdHa2goCBVqFBBFoslveMDAAAAAAAAgGwnTYVbSbJYLKpYsaLNsk8++UQ9evTgBmUAAAAAAAAAcBdcvjkZAAAAAAAAACBjUbgFAAAAAAAAAA9D4RYAAAAAAAAAPAyFWwAAAAAAAADwME7dnOzixYtONXblypW7CgYAAAAAAAAA4GThNjg4WBaL5Y7bGYbh1HYAAAAAAAAAAMecKty+9NJLFGQBAAAAAAAAIJM4VbgNDw/P4DAAAAAAAAAAAIm4ORkAAAAAAAAAeBgKtwAAAAAAAADgYSjcAgAAAAAAAICHoXALAAAA/J833nhDly5dcncYAAAAAIVbAAAAINHzzz+vYsWKaejQoTp48KC7wwEAAEA25nLh9ubNmxkRBwAAAOB2f/31l0aMGKH169erVq1aatKkiVatWqX4+Hh3hwYAAIBsxuXCbdGiRTV+/HidOnUqI+IBAAAA3CYsLEzTp0/Xv//+q7fffluxsbHq3bu3SpQoofDwcEVGRro7RAAAAGQTLhduO3furDfffFNlypRR165d9e2332ZEXAAAAIDb+Pv767HHHtNPP/2k77//XuXLl9eUKVNUsmRJ9erVi2kUAAAAkOFcLty+9957+vfff/Xqq6/q4MGDatu2re677z7Nnz9fV65cyYgYAQAAALf45ptv9Prrr2vnzp0qUKCA+vTpo+3bt6tOnTp655133B0eAAAA7mFpujlZ/vz5NXbsWP31119at26dihcvrmeeeUZFixbVU089pSNHjqR3nAAAAECmuHLlit58801VrFhRbdu21fHjx/XWW2/pn3/+0XvvvaeTJ0+qf//+Cg8Pd3eoAAAAuIelqXCbyGKx6MEHH9Trr7+uZs2a6erVq1q4cKEqV66sRx55RFFRUekVJwAAAJDhnnzySRUtWlRjxoxRxYoV9e233+rQoUMaMmSIAgICJEm+vr4aNGiQzpw54+ZoAQAAcC9Lc+E2Pj5eK1euVJMmTVSnTh0dP35cr7/+uk6ePKk5c+Zox44d6t+/f3rGCgAAAGSoVatWaejQoTp27JjWr1+vFi1a2N2uYsWKWrp0aSZHBwAAgOzEx9UdTp8+rcWLF+vtt9/WuXPn1LRpU3300Ufq2rWrvLxu14FHjhypokWLqm/fvukeMAAAAJBR/v33X+XKleuO2wUHB2vAgAGZEBEAAACyK5dH3JYsWVIzZsxQ+/bttX//fn333Xd65JFHzKJtotKlS6tgwYLpFigAAACQ0apWraqDBw/aXffLL7+odOnSmRwRAAAAsiuXR9y+/PLLGjZsmEJCQlLdrkaNGjpx4kSaAwMAAAAy28mTJxUXF2d3XWxsrP7+++9MjggAAADZlcuF24kTJ2ZEHAAAAIBHsFgsdpcfP35cefLkyeRoAAAAkF25XLiVpJiYGC1YsEBbt25VdHS0goKC1KJFCz355JPKly9fOocIAAAAZJz3339f77//vvn4ySefVGBgoM02N27c0MGDB9WsWbPMDg8AAADZlMuF2xMnTqhFixY6deqUwsLCVKhQIR07dkzffPON3nrrLW3dupW5vwAAAJBlXL9+XefPn5d0e7Ttf//9l2K6BH9/f/Xs2VOTJk1yR4gAAADIhlwu3D7zzDOKjY3V999/r4YNG5rLd+3apYcfflijRo3Sp59+mq5BAgAAABnlySef1JNPPilJKlWqlD755BNVr17dzVEBAAAgu3O5cLtlyxbNnTvXpmgrSY0aNdIrr7yiUaNGpVdsAAAAQKbi5roAAADwFF6u7uDv76/ixYvbXVeiRAn5+/vfdVAAAAAAAAAAkJ25XLjt0qWL1qxZY3fdmjVr1KlTJ5eDWLhwoUqVKqWAgADVrl1bO3bscLjt2rVr1aZNG4WEhCgwMFANGzbUV199lWK7Tz75RJUqVZK/v78qVaqkdevWuRwXAAAA7n3e3t768ccfJUleXl7y9vZ2+OPjk6Z7+wIAAAAuc7nn2bt3bw0ePFjdu3dX7969VahQIZ09e1YffvihfvrpJ7377rvav3+/uX2tWrVSbW/16tUaNWqUFi5cqMaNG2vx4sXq0KGDfvvtN5UoUSLF9tu3b1ebNm00depU5cuXT0uXLlXnzp31ww8/qGbNmpKk3bt3q2fPnpoyZYq6du2qdevWqUePHtq5c6fq16/v6ikDAADgHvbSSy+pWLFi5u8Wi8XNEQEAAABpKNy2bdtWkvTPP/9o7dq15nLDMGzWG4Yhi8WihISEVNubNWuWBg8erCFDhkiS5syZo6+++kqLFi3StGnTUmw/Z84cm8dTp07Vhg0btHHjRrNwO2fOHLVp00bjx4+XJI0fP17fffed5syZo5UrV7p6ygAAALiHvfzyy+bv4eHh7gsEAAAASMLlwu3SpUvT7eA3b97Uvn37NG7cOJvlbdu21a5du5xqw2q16sqVKypQoIC5bPfu3Ro9erTNdu3atUtR9E0qLi5OcXFx5uOYmBizfavV6lQs6cJQ5h4vC7BarTIMg7zYQW7sIy+OkRv7yItj5MY+8uJYZucmvY+TOPjAkZiYGAUGBqbrMQEAAAB7XC7cDhgwIN0OfuHCBSUkJKhgwYI2ywsWLKizZ8861cYbb7yha9euqUePHuays2fPutzmtGnTNGnSpBTLz58/r9jYWKdiuRtW6+2RyQnWBEVFRWX48bISq9Wqy5cvyzAMeXm5PC3zPY3c2EdeHCM39pEXx8iNfeTFsczOzZUrV9K1vVatWmnVqlUKDQ1NsW7v3r169NFH9ddff6XrMQEAAAB77uruCkePHlV0dLSCg4NVrly5NLeTfFTDnUY6JFq5cqXCw8O1YcOGFJ1rV9scP368xowZYz6OiYlR8eLFzZugZTQvL29J8fL28rb7QSE7s1qtslgsCgkJ4cNxMuTGPvLiGLmxj7w4Rm7sIy+OZXZuAgIC0rW93377TdWrV9eHH36oli1bmsvnzp2rsWPHqnr16ul6PAAAAMCRNBVu16xZo2effVb//vuvuaxYsWJ644031K1bN6fbCQ4Olre3d4qRsFFRUSlGzCa3evVqDR48WGvWrFHr1q1t1iXeMM2VNv39/eXv759iuZeXV+Z+ILOID4B2WCyWzH8usghyYx95cYzc2EdeHCM39pEXxzIzN+l9jIMHD6p3795q166dJkyYoJEjR2rw4MH69NNP9dRTT2nmzJnpejwAAADAEZd7ups2bdKjjz6qvHnz6rXXXtOyZcs0bdo05c2bV48++qi++OILp9vy8/NT7dq1tXnzZpvlmzdvVqNGjRzut3LlSg0cOFArVqxQx44dU6xv2LBhija//vrrVNsEAAAAChYsqG+++UYvvPCCXn31VRUrVkzbt2/Xxx9/rDfffFN+fn7uDhEAAADZhMsjbl999VW1bdtWn3/+uc0Ih+eee04dOnTQK6+8og4dOjjd3pgxY9SvXz/VqVNHDRs21JIlS3Tq1Ck98cQTkm5PYXD69GktW7ZM0u2ibf/+/TV37lw1aNDAHFmbI0cO5c2bV5L0zDPP6P7779frr7+uLl26aMOGDfrmm2+0c+dOV08XAAAA2YzFYlFQUJC8vLwUFxenkiVLqlKlSu4OCwAAANmMyyNuDxw4oOHDh6e4LM1isWj48OE6ePCgS+317NlTc+bM0eTJk1WjRg1t375dmzZtUlhYmCQpMjJSp06dMrdfvHix4uPjNWLECBUuXNj8eeaZZ8xtGjVqpFWrVmnp0qWqVq2aIiIitHr1atWvX9/V0wUAAEA2cuXKFXXv3l2jR4/W0KFDtXfvXklS3bp1tXz5cjdHBwAAgOzE5RG33t7eunnzpt11t27dStM8Y8OHD9fw4cPtrouIiLB5vG3bNqfa7Natm0vz7QIAAAC1atVSVFSUVq1ape7du0uS9u3bp2HDhmnAgAHatm2b3n33XTdHCQAAgOzA5Spr3bp1NX36dN24ccNmeVxcnGbOnMmoVgAAAGRZefLk0b59+8yirSTlzJlTy5cv15IlS7Rq1So3RgcAAIDsxOURt5MmTVKrVq1UunRpde/eXYUKFVJkZKTWrl2r6OhobdmyJSPiBAAAADLc7t275e/vb3fdkCFD1KBBg0yOCAAAANmVy4XbJk2aaPPmzXr++ee1YMECGYYhLy8v1a9fXytXrlSjRo0yIk4AAAAgwyUWbS9fvqw9e/bowoULeuCBB5Q/f35JUpUqVdwZHgAAALIRlwq3sbGxWrZsmZo2bardu3fr+vXrunTpkvLnz6+cOXNmVIwAAABAppkyZYpee+013bhxQxaLRXv37lX+/PnVqlUrtWnTRuPGjXN3iAAAAMgGXJrjNiAgQE8//bSioqIk3Z7vq2jRohRtAQAAcE9YuHChJk2apMGDB+vzzz+XYRjmuk6dOunzzz93Y3QAAADITlyeKqF06dI6e/ZsRsQCAAAAuNX8+fM1ZswYTZ8+XQkJCTbrypUrp2PHjrkpMgAAAGQ3Lo24laRnnnlGr732mmJiYjIiHgAAAMBtjh8/rnbt2tldlydPHv3333+ZGxAAAACyLZdH3P7666+6cOGCSpYsqZYtW6pw4cKyWCzmeovForlz56ZrkAAAAEBmyJs3r86dO2d33cmTJxUaGprJEQEAACC7crlwO3/+fPP3tWvXplhP4RYAAABZVatWrTR9+nR16dJFAQEBkm73b+Pj47Vo0SKHo3EBAACA9OZy4dZqtWZEHAAAAIDbTZ48WXXr1lWlSpXUtWtXWSwWzZ8/Xz///LNOnTqljz76yN0hAgAAIJtweY7bU6dO6datW3bXxcfH69SpU3cdFAAAAOAOZcuW1ffff6/77rtPCxculGEYWrZsmYKDg7Vjxw6VKFHC3SECAAAgm3B5xG2pUqW0e/du1atXL8W6gwcPql69einuwAsAAABkFZUqVdKXX36puLg4RUdHK3/+/MqRI4e7wwIAAEA243Lh1jAMh+sSEhJsblQGAAAAZFX+/v4qUqSIu8MAAABANuVy4VaS3eJsXFycvvjiCwUHB991UAAAAEBmWbZsmUvb9+/fP4MiAQAAAP4/pwq3kyZN0uTJkyXdLto2aNDA4bZDhgxJn8gAAACATDBw4ECnt7VYLBRuAQAAkCmcKtzWq1dPw4cPl2EYWrhwobp166aCBQvabOPv76+qVauqd+/eGRIoAAAAkBFOnDjh7hAAAACAFJwq3Hbo0EEdOnSQJF27dk0vvfSSSpUqlaGBAQAAAJkhLCzM3SEAAAAAKbg8x+3SpUszIg4AAADAY8TGxmr//v2Kjo5WUFCQatWqpYCAAHeHBQAAgGwkTTcnu3Llir744gv9/fffunHjhs06i8WiF198MV2CAwAAADLbrFmzNGXKFMXExMgwDFksFuXJk0cvvvii/ve//7k7PAAAAGQTLhduf/jhB3Xs2FEXL160u57CLQAAALKqefPm6dlnn1WbNm3Uu3dvFSpUSGfPntWHH36osWPHytfXV08//bS7wwQAAEA24HLhdvTo0SpatKi+/PJLVatWTX5+fhkRFwAAAJDp5syZo759+2rZsmU2ywcMGKC+fftq7ty5FG4BAACQKbxc3eHw4cN65ZVXVKdOHYq2AAAAuKecOXNGffr0sbuuX79+OnPmTCZHBAAAgOzK5cJtSEhIRsQBAAAAuF358uV17tw5u+siIyNVtmzZTI4IAAAA2ZXLhduRI0fqrbfekmEYGREPAAAA4DaTJk3Syy+/rF9++cVm+aFDhzRp0iRNnjzZqXa2b9+uzp07q0iRIrJYLFq/fn2q269du1Zt2rRRSEiIAgMD1bBhQ3311VdpPQ0AAADcA1ye49ZqterIkSOqWbOmOnbsqKCgIJv1FotFo0ePTrcAAQAAgMzy3nvvKT4+XjVq1FDlypXNm5P9+uuvKlKkiJYuXaqlS5dKut3v3bBhg912rl27purVq2vQoEF65JFH7njc7du3q02bNpo6dary5cunpUuXqnPnzvrhhx9Us2bNdD1HAAAAZA0uF26fe+458/dDhw6lWE/hFgAAAFnVoUOH5OPjo+LFiysmJkYxMTGSpOLFi0u6fb+HRBaLxWE7HTp0UIcOHZw+7pw5c2weT506VRs2bNDGjRsp3AIAAGRTLhduT5w4kRFxAAAAAG538uRJd4cg6fZVbleuXFGBAgUcbhMXF6e4uDjzcWKR2Wq1ymq1ZniMSjJ1WqYcLwuxWq0yDIO82EFu7CMvjpEb+8iLY+TGPvLiWGbnxpXjuFy4DQsLc3UXAAAAwOPduHFDgwcP1vDhw9WkSRO3xvLGG2/o2rVr6tGjh8Ntpk2bpkmTJqVYfv78ecXGxmZkeJKk+IQESZJhGIqKipKXl8u3z7hnWa1WXb58WYZhkJdkyI195MUxcmMfeXGM3NhHXhzL7NxcuXLF6W2dKtyeOnVKhQsXlq+v7x0PvHfvXrVs2dLpAAAAAABPkCNHDm3YsEFPPPGEW+NYuXKlwsPDtWHDBoWGhjrcbvz48RozZoz5OCYmRsWLFzdvcJbRfLyPSLo9ZURoaCgfApOwWq2yWCwKCQkhL8mQG/vIi2Pkxj7y4hi5sY+8OJbZuQkICHB6W6cKt6VKldLu3btVr149SbdPqGLFilq/fr0qVapkbvfbb7+pTZs2Svi/b98BAACArKRGjRr65ZdfdP/997vl+KtXr9bgwYO1Zs0atW7dOtVt/f395e/vn2K5l5dX5nwgSzLHb6YdMwuxWCzkxQFyYx95cYzc2EdeHCM39pEXxzIzN64cw6ktjSTzVyU+/vPPPzPlEiwAAAAgs7z22muaPn26vvvuu0w/9sqVKzVw4ECtWLFCHTt2zPTjAwAAwLO4PMctAAAAcK8aPny4rl69qpYtWyp//vwqXLiwLElGllosFh08ePCO7Vy9elV//vmn+fjEiRM6cOCAChQooBIlSmj8+PE6ffq0li1bJul20bZ///6aO3euGjRooLNnz0q6PX1D3rx50/ksAQAAkBVQuAUAAAD+T1BQkIKDg++6nZ9++kktWrQwHyfORTtgwABFREQoMjJSp06dMtcvXrxY8fHxGjFihEaMGGEuT9weAAAA2Q+FWwAAAOD/bNu2LV3aad68eYrpxpJKXoxNr+MCAADg3uF04TYmJkYXL16UJMXHx6dYJkmXL19O5/AAAAAAAAAAIPtxunDbrl27FMtatWqVrsEAAAAA7nb+/HnNmjVL27Zt04ULF7R+/XpVrlxZixcvVr169VSzZk13hwgAAIBswKnC7csvv5zRcQAAAABud+LECTVu3FiXL19W9erVdfz4ccXFxUmSDh06pD179mjp0qVujhIAAADZAYVbAAAA4P+MHTtW+fLl008//aTQ0FD5+fmZ65o0aUK/GAAAAJmGm5MBAAAA/+fbb7/VokWLVKRIESUkJNisK1y4sM6cOeOmyAAAAJDdeN3NzgkJCfL29tb+/fvTKx4AAADAbWJjY1WgQAG7665duyYvr7vqPgMAAABOu+uep2EY6REHAAAA4HYVKlTQN998Y3fd9u3bVaVKlUyOCAAAANmVRwwZWLhwoUqVKqWAgADVrl1bO3bscLhtZGSkevfurQoVKsjLy0ujRo1KsU1ERIQsFkuKn9jY2Aw8CwAAAGR1Q4cO1Zw5czR37lxdunRJknTz5k19/PHHWrhwoYYNG+bmCAEAAJBduL1wu3r1ao0aNUoTJkzQzz//rKZNm6pDhw46deqU3e3j4uIUEhKiCRMmqHr16g7bDQwMVGRkpM1PQEBARp0GAAAA7gHDhw/XgAEDNHr0aBUqVEjS7ZuS9ezZU3369NGAAQPcHCEAAACyi7u6OZm3t7eWLl2qUqVKpbmNWbNmafDgwRoyZIgkac6cOfrqq6+0aNEiTZs2LcX2JUuW1Ny5cyVJ7733nsN2LRaL2dkGAAAAUnPjxg2tX79ef//9t+rXr6++fftq8+bNOnfunIKDg9WpUyc1atTI3WECAAAgG7mrwq2kuxp1cPPmTe3bt0/jxo2zWd62bVvt2rXrruK6evWqwsLClJCQoBo1amjKlCmqWbPmXbUJAACAe8+ZM2d0//3368SJEzIMQxaLRYGBgdq0aZMaNmzo7vAAAACQTblcuN2yZYuio6PVvXt3SdK5c+c0aNAg7d+/X23bttWSJUucnpLgwoULSkhIUMGCBW2WFyxYUGfPnnU1NFPFihUVERGhqlWrKiYmRnPnzlXjxo118OBBlStXzu4+cXFxiouLMx/HxMRIkqxWq6xWa5pjcZmhzD1eFmC1WmUYBnmxg9zYR14cIzf2kRfHyI195MWxzM5Nehxn4sSJOn36tCZOnKgGDRro2LFjevXVVzV8+HD9/PPP6RAlAAAA4DqXC7cvvfSS2rRpYz4eO3asduzYoTZt2ujjjz9WuXLl9OKLL7rUpsVisXmcONIhrRo0aKAGDRqYjxs3bqxatWpp3rx5evPNN+3uM23aNE2aNCnF8vPnz2fKTc2s1gRJUoI1QVFRURl+vKzEarXq8uXLMgxDXl5un5bZo5Ab+8iLY+TGPvLiGLmxj7w4ltm5uXLlyl23sXnzZr3wwgtmH7ZDhw4qU6aMHnzwQZ07dy7FIAMAAAAgM7hcuD169Kief/55SVJ8fLzWrVun119/XcOHD9fMmTP13nvvOV24DQ4Olre3d4rRtVFRUenaQfby8lLdunV17Ngxh9uMHz9eY8aMMR/HxMSoePHiCgkJUWBgYLrF4jhGb0nx8vbyVmhoaIYfLyuxWq2yWCwKCQnhw3Ey5MY+8uIYubGPvDhGbuwjL45ldm7S4+azZ8+e1f3332+zrHnz5jIMg8ItAAAA3Mblwm1MTIzy5csnSdq3b5+uXbumBx98UJJUr149hYeHO92Wn5+fateurc2bN6tr167m8s2bN6tLly6uhuaQYRg6cOCAqlat6nAbf39/+fv7p1ju5eWVuR/ILOIDoB0WiyXzn4ssgtzYR14cIzf2kRfHyI195MWxzMxNehwjISFBOXLksFmWWBCOj4+/6/YBAACAtHC5cBsaGqpjx46padOm+uabbxQWFqZixYpJun2pmq+vr0vtjRkzRv369VOdOnXUsGFDLVmyRKdOndITTzwh6fZI2NOnT2vZsmXmPgcOHJB0+wZk58+f14EDB+Tn56dKlSpJkiZNmqQGDRqoXLlyiomJ0ZtvvqkDBw5owYIFrp4uAAAAsoE//vhDPj7/v2uckHB7GqsjR46k2LZWrVqZFhcAAACyL5cLt+3bt9cLL7ygX3/9VRERERowYIC57siRIypZsqRL7fXs2VPR0dGaPHmyIiMjVaVKFW3atElhYWGSpMjISJ06dcpmn5o1a5q/79u3TytWrFBYWJhOnjwpSfrvv//0+OOP6+zZs8qbN69q1qyp7du3q169eq6eLgAAALKBgQMH2l3er18/8/fE+zAkFnUBAACAjORy4Xbq1Kk6deqU3n77bdWrV08TJ040161YsUKNGjVyOYjhw4dr+PDhdtdFRESkWGYYRqrtzZ49W7Nnz3Y5DgAAAGQ/S5cudXcIAAAAQAouF26Dg4P15Zdf2l23devWdLlBBAAAAJBZkl5BBgAAAHiKdLljRGxsrI4cOaJcuXLJz88vPZoEAAAAAAAAgGzL5cLtvHnzNGXKFPPxvn37VLx4cVWuXFnly5fXP//8k64BAgAAAAAAAEB243Lh9p133lG+fPnMx88//7wKFCig2bNnyzAMvfLKK+kZHwAAAAAAAABkOy7PcXvq1ClVrFhRknTlyhVt375dq1at0sMPP6z8+fPrpZdeSvcgAQAAAAAAACA7cXnEbVxcnHx9fSVJu3fvltVqVevWrSVJJUuW1NmzZ9M3QgAAAAAAAADIZlwu3JYoUUI7duyQJG3YsEE1atRQYGCgJOn8+fPm7wAAAAAAAACAtHF5qoS+fftq0qRJWr9+vQ4ePKiZM2ea63766SeVL18+XQMEAAAAAAAAgOzG5cLthAkT5OPjo127dqlr164aOXKkue6XX37RI488kq4BAgAAAAAAAEB243Lh1mKxaNy4cXbXffrpp3cdEAAAAAAAAABkdy4XbhNduXJFu3fvVnR0tIKDg9WgQQPlyZMnPWMDAAAAAAAAgGwpTYXbmTNnatKkSbp+/boMw5DFYlHOnDk1adIkjRkzJr1jBAAAAAAAAIBsxeXC7bJlyzR27Fh16NBBAwcOVJEiRXTmzBm9//77eu655xQSEqJ+/fplRKwAAAAAAAAAkC24XLidPXu2evfurQ8++MBmeffu3dW3b1/Nnj2bwi0AAAAAAAAA3AUvV3c4cuSI+vbta3dd37599fvvv991UAAAAAAAAACQnblcuM2RI4cuXrxod93FixeVI0eOuw4KAAAAAAAAALIzlwu3TZs2VXh4uM6cOWOz/OzZs5o8ebLuv//+dAsOAAAAAAAAALIjl+e4ffXVV9WoUSOVLVtWrVq1UuHChRUZGaktW7bI19dXa9euzYg4AQAAAAAAACDbcHnEbZUqVfTTTz+pS5cu2rt3r5YuXaq9e/fqoYce0o8//qhKlSplRJwAAAAAAAAAkG24NOI2NjZWkydP1iOPPKKVK1dmVEwAAAAAAAAAkK25NOI2ICBAs2fP1rVr1zIqHgAAAAAAAADI9lyeKuG+++7TiRMnMiIWAAAAAAAAAIDSULh98cUX9corr+ivv/7KiHgAAAAAAAAAINtzaY5bSVq6dKmuX7+u++67T9WqVVPhwoVlsVjM9RaLRRs2bEjXIAEAAAAAAAAgO3G5cHvo0CH5+fmpaNGiio6OVnR0tM36pEVcAAAAAAAAAIDrXC7cnjx5MgPCAAAAAAAAAAAkcnmOWwAAAAAAAABAxnKqcHvp0iU98sgj+uyzzxxu89lnn+mRRx5JMXUCAAAAAAAAAMA1ThVu33nnHR08eFDt27d3uE379u11+PBhLViwIN2CAwAAAAAAAIDsyKnC7apVqzR06FD5+DieEtfHx0dDhw7Vp59+mm7BAQAAAAAAAEB25FTh9ujRo6pTp84dt6tVq5aOHj1610EBAAAAAAAAQHbmVOE2Pj5evr6+d9zO19dXt27duuugAAAAAAAAACA7c6pwW7hwYf3222933O7XX39VoUKF7jooAAAAAAAAAMjOnCrcNmvWTAsXLkx1NO2tW7e0aNEitWjRIt2CAwAAAAAAAIDsyKnC7ejRo3XkyBF17dpVZ86cSbH+zJkzeuihh/THH39o9OjR6R4kAAAAAAAAAGQnPs5sVK1aNS1YsEDDhw9XqVKlVLt2bZUqVUqSdOLECe3bt09Wq1WLFi1S1apVMzRgAAAAAAAAALjXOVW4laShQ4eqSpUqmjp1qrZu3ao9e/ZIknLmzKn27dtr/PjxatCgQYYFCgAAAAAAAADZhdOFW0lq2LChNm7cKKvVqgsXLkiSgoOD5eXl1IwLAAAAAAAAAAAnuFS4TeTl5aXQ0ND0jgUAAAAAAAAAICdvTgYAAAAAAAAAyDwUbgEAAAAAAADAw1C4BQAAAAAAAAAP4xGF24ULF6pUqVIKCAhQ7dq1tWPHDofbRkZGqnfv3qpQoYK8vLw0atQou9t98sknqlSpkvz9/VWpUiWtW7cug6IHAAAAAAAAgPTl9sLt6tWrNWrUKE2YMEE///yzmjZtqg4dOujUqVN2t4+Li1NISIgmTJig6tWr291m9+7d6tmzp/r166eDBw+qX79+6tGjh3744YeMPBUAAAAAAAAASBduL9zOmjVLgwcP1pAhQ3Tfffdpzpw5Kl68uBYtWmR3+5IlS2ru3Lnq37+/8ubNa3ebOXPmqE2bNho/frwqVqyo8ePHq1WrVpozZ04GngkAAAAAAAAApA8fdx785s2b2rdvn8aNG2ezvG3bttq1a1ea2929e7dGjx5ts6xdu3apFm7j4uIUFxdnPo6JiZEkWa1WWa3WNMfiMkOZe7wswGq1yjAM8mIHubGPvDhGbuwjL46RG/vIi2OZnRueAwAAANyr3Fq4vXDhghISElSwYEGb5QULFtTZs2fT3O7Zs2ddbnPatGmaNGlSiuXnz59XbGxsmmNxltWaIElKsCYoKioqw4+XlVitVl2+fFmGYcjLy+2DxD0KubGPvDhGbuwjL46RG/vIi2OZnZsrV65k+DEAAAAAd3Br4TaRxWKxeWwYRoplGd3m+PHjNWbMGPNxTEyMihcvrpCQEAUGBt5VLM7w8vKWFC9vL2+FhoZm+PGyEqvVKovFopCQED4cJ0Nu7CMvjpEb+8iLY+TGPvLiWGbnJiAgIMOPAQAAALiDWwu3wcHB8vb2TjESNioqKsWIWVcUKlTI5Tb9/f3l7++fYrmXl1fmfiCziA+Adlgslsx/LrIIcmMfeXGM3NhHXhwjN/aRF8cyMzfkHwAAAPcqt/Z0/fz8VLt2bW3evNlm+ebNm9WoUaM0t9uwYcMUbX799dd31SYAAAAAAAAAZBa3T5UwZswY9evXT3Xq1FHDhg21ZMkSnTp1Sk888YSk21MYnD59WsuWLTP3OXDggCTp6tWrOn/+vA4cOCA/Pz9VqlRJkvTMM8/o/vvv1+uvv64uXbpow4YN+uabb7Rz585MPz8AAAAAAAAAcJXbC7c9e/ZUdHS0Jk+erMjISFWpUkWbNm1SWFiYJCkyMlKnTp2y2admzZrm7/v27dOKFSsUFhamkydPSpIaNWqkVatWaeLEiXrxxRdVpkwZrV69WvXr18+08wIAAAAAAACAtHJ74VaShg8fruHDh9tdFxERkWKZYRh3bLNbt27q1q3b3YYGAAAAAAAAAJmOuzkAAAAAAAAAgIehcAsAAAAAAAAAHobCLQAAAAAAAAB4GAq3AAAAAAAAAOBhKNwCAAAAAAAAgIehcAsAAACks+3bt6tz584qUqSILBaL1q9fn+r2kZGR6t27typUqCAvLy+NGjUqU+IEAACA56JwCwAAAKSza9euqXr16po/f75T28fFxSkkJEQTJkxQ9erVMzg6AAAAZAU+7g4AAAAAuNd06NBBHTp0cHr7kiVLau7cuZKk9957L6PCAgAAQBZC4RYAAADIguLi4hQXF2c+jomJkSRZrVZZrdaMD8AwzF8z5XhZiNVqlWEY5MUOcmMfeXGM3NhHXhwjN/aRF8cyOzeuHIfCLQD8v/buPT6q+s7/+PvM5CbWoIQQEgkQqHKRixishIqBsoWCutrqo3R3S7FVVxZvkPpwDb1YXB8PVteHUmqRWhFKa4u75cd6Y2uwhlArWsEgFwWloEGbEIJCApRAMt/fH8lMMplzJjMxmTmTeT0fzIPMOZ9zznc+883MJ5+cnAEAIAEtXbpUS5YsCVl+5MgRnT59useP39TcLEkyxqi2tlYeD1dh8/P5fDp+/LiMMeSlA3Jjj7w4Izf2yIszcmOPvDiLdW4aGhoijqVxCwAAACSg0tJSlZSUBO7X19crPz9f2dnZyszM7PHjp3j3SpIsy9KAAQP4IbAdn88ny7KUnZ1NXjogN/bIizNyY4+8OCM39siLs1jnJiMjI+JYGrcAAABAAkpPT1d6enrIco/HE5sfyCwr9sdMIJZlkRcH5MYeeXFGbuyRF2fkxh55cRbL3ERzDJ4pAAAAAAAAAHAZzrgFAAAAutmJEye0f//+wP2DBw9qx44d6tevnwYPHqzS0lJ98sknWrt2bSBmx44dgW2PHDmiHTt2KC0tTaNHj4718AEAAOACNG4BAACAbrZt2zZNmzYtcN9/Ldp58+ZpzZo1qq6uVlVVVdA2EyZMCHy9fft2/fa3v9WQIUP04YcfxmTMAAAAcBcatwAAAEA3mzp1qowxjuvXrFkTsixcPAAAAJIP17gFAAAAAAAAAJehcQsAAAAAAAAALkPjFgAAAAAAAABchsYtAAAAAAAAALgMjVsAAAAAAAAAcBkatwAAAAAAAADgMjRuAQAAAAAAAMBlaNwCAAAAAAAAgMvQuAUAAAAAAAAAl6FxCwAAAAAAAAAuQ+MWAAAAAAAAAFyGxi0AAAAAAAAAuAyNWwAAAAAAAABwGRq3AAAAAAAAAOAyNG4BAAAAAAAAwGVo3AIAAAAAAACAy9C4BQAAAAAAAACXoXELAAAAAAAAAC5D4xYAAAAAAAAAXIbGLQAAAAAAAAC4DI1bAAAAAAAAAHAZGrcAAAAAAAAA4DI0bgEAAAAAAADAZWjcAgAAAAAAAIDL0LgFAAAAAAAAAJdxReN2xYoVKigoUEZGhgoLC/WnP/0pbHxFRYUKCwuVkZGhYcOGaeXKlUHr16xZI8uyQm6nT5/uyYcBAAAAAAAAAN0i7o3bZ599VgsXLtQPfvADVVZWasqUKZo1a5aqqqps4w8ePKjZs2drypQpqqys1OLFi3XXXXdp/fr1QXGZmZmqrq4OumVkZMTiIQEAAAAAAADA55IS7wE8+uijuvnmm3XLLbdIkpYtW6aXX35ZTzzxhJYuXRoSv3LlSg0ePFjLli2TJI0aNUrbtm3TI488ohtuuCEQZ1mWBg4cGJPHAAAAAAAAAADdKa6N2zNnzmj79u267777gpbPmDFDr7/+uu02W7du1YwZM4KWzZw5U6tWrdLZs2eVmpoqSTpx4oSGDBmi5uZmXXrppfqP//gPTZgwwXEsjY2NamxsDNyvr6+XJPl8Pvl8vi49vi4xiu3xEoDP55MxhrzYIDf2yIszcmOPvDgjN/bIi7NY54bnAAAAAL1VXBu3dXV1am5uVk5OTtDynJwc1dTU2G5TU1NjG9/U1KS6ujrl5uZq5MiRWrNmjcaOHav6+nr99Kc/1Ze//GW98847uuiii2z3u3TpUi1ZsiRk+ZEjR2JybVyfr1mS1OxrVm1tbY8fL5H4fD4dP35cxhh5PHG/uoerkBt75MUZubFHXpyRG3vkxVmsc9PQ0NDjxwAAAADiIe6XSpBaLmvQnjEmZFln8e2XT5o0SZMmTQqs//KXv6zLLrtMP/vZz7R8+XLbfZaWlqqkpCRwv76+Xvn5+crOzlZmZmZ0D6gLPB6vpCZ5PV4NGDCgx4+XSHw+nyzLUnZ2Nj8cd0Bu7JEXZ+TGHnlxRm7skRdnsc4Nn2EAAACA3iqujdv+/fvL6/WGnF1bW1sbclat38CBA23jU1JSlJWVZbuNx+PR5Zdfrg8++MBxLOnp6UpPT7fdNqY/kFniB0AblmXF/rlIEOTGHnlxRm7skRdn5MYeeXEWy9yQfwAAAPRWca1009LSVFhYqE2bNgUt37RpkyZPnmy7TVFRUUh8WVmZJk6cGLi+bUfGGO3YsUO5ubndM3AAAAAAAAAA6EFxP0WhpKRETz31lJ5++mm99957WrRokaqqqjR//nxJLZcw+M53vhOInz9/vj766COVlJTovffe09NPP61Vq1bpnnvuCcQsWbJEL7/8sg4cOKAdO3bo5ptv1o4dOwL7BAAAAAAAAAA3i/s1bufMmaOjR4/qgQceUHV1tcaMGaONGzdqyJAhkqTq6mpVVVUF4gsKCrRx40YtWrRIP//5z5WXl6fly5frhhtuCMQcO3ZM//qv/6qamhr17dtXEyZM0JYtW/SlL30p5o8PAAAAAAAAAKIV98atJC1YsEALFiywXbdmzZqQZcXFxXr77bcd9/fYY4/pscce667hAQAAAAAAAEBMxf1SCQAAAAAAAACAYDRuAQAAAAAAAMBlaNwCAAAAAAAAgMvQuAUAAAAAAAAAl6FxCwAAAAAAAAAuQ+MWAAAAAAAAAFyGxi0AAAAAAAAAuAyNWwAAAAAAAABwGRq3AAAAAAAAAOAyNG4BAAAAAAAAwGVo3AIAAAAAAACAy9C4BQAAAAAAAACXoXELAAAAAAAAAC5D4xYAAAAAAAAAXIbGLQAAAAAAAAC4DI1bAAAAAAAAAHAZGrcAAAAAAAAA4DI0bgEAAAAAAADAZWjcAgAAAAAAAIDL0LgFAAAAAAAAAJehcQsAAAAAAAAALkPjFgAAAAAAAABchsYtAAAAAAAAALgMjVsAAAAAAAAAcBkatwAAAAAAAADgMjRuAQAAAAAAAMBlaNy6QLPP6EyTT5LUeLZZzT4T5xEBAAAAAAAAiCcat3H2h93VuvKhV3Xs72clSUdPntWVD72qP+yujvPIAAAAAGfGtJxs0NRs9MaBo5x8AAAA0M1S4j2AZLb95bXatWWLvi5J3rbl1glp1++k7KuuUuHM78RreHC5Zp/RmweOav/Hn+qLJ7y6Ylh/eT1WvIcFAEhGxw5Jp46q2Rjt/viYDtUeU/6A8zVm0PnyWpbUJ0s6Pz/eo0R3efdFvb/7L5r1abV83pZm7Wur/5/eSU/R9JEDdPGYL0mjr4nzIOFG1K8AANdIkPqVxm2cNO95QZdtvVOFqc4xZuv/qD7nPHlHXSuvx1KKx5LXY8myKG6S2rFDen3XPv1iywHVnTgTWNz/C2m67aphmjx2hCteXOAiCfKGBBdhziAaxw5JjxdKTY3yShrfeguSki7dsZ150xu8+6LMf/+LLpZ0T8c61ifpXcm8K1nffIbmLdpQvyJa1CKIFnMG0Uig+pXGbZx88v7bGtxJjCVp5f+8pBXNaUHLvR5LXstqa+Z625q6Xst/3xPU7PXfUgL/exyWW/J6PPJ6JK/HE7zc27J/f0yK1woeizeCfQQdM3SMQeNrfVwyRsf/3qSM02eVluINrPdYSr4m9rFDal5+mSb7zmiyJKW3W3dW0h+l5vI0ee96O+4vLnCJBHpDgkswZxCtU0elpsbwMU2NLXHMmYTXfOTd9n8oZsuStKHsFW2qzG2pCS3J065m9N88He57LSsQl+L1r1cgLsXTtj40ruV/fy3ZFqfWmlPBcd7g/XQ+LgXikq7+/LyoXxEtahFEizmDaCVQ/UrjNk7qG5siihulj/SPnj9LsmQkGVktNyOZZktqlszZlnUhMa1fK7DMH9PytU+WmgPr27YLxBv/NgraX/A+O8a0P679GOzGZ7d9aEzr4263zuPxyOOx5GltArcU2p7W+57AcsvjaS22W+Na11seS16PV572DWevR5bV2tj2eluXtaxvWd4Sk+L1BDWmOzbA2+/Tfnm75rU3+IeNFG+78QSa8ZZSjlQry9d2loIdr++MGuuPyHvehYFl/h8w2v+Y0f5nDn4A6cUS6A0JLsGcQWeMCfq62efrtJEnSc3GRBQHdzt09O8aGkFc45G/6rPaPwZqSql9vanW+5ZtLRgcG3xfIfcVUjM61ZmRxbbVm+3Xtx+fZam1gdtWh3qsllrOX3N6PJaM8SklJbW1TvTIao3zWpas1jrQX3N6WveX4q9b29e3/v0Hak6PPK3H9te2nTfDJa/XXw8rbNPcf7JGuCZ2JM1wf83rOV6rcyKoX5tP1snL+wokahFEjzmDKEVal7qhfqVxGyd/j7Bxe23qX3St/tLDo+lFjKTm1luM+Ey4HwDsGt4dm96dN7j9DXdLTcHdVwfHV12vMwpzHQ4H/h+sAtrdNXYLO9ufQ2z75ZbD8tBtOrBCvgjZ4EObhrQVdlyhrMA6K3ShnB9LyDYdltutcXqM4cYc7vkwspRuGjXEMaLNh7/8F52xMiKI7FxPfjRNuDny+fdt9FlPfmZnD/9+pLtyk+E7rWERxB385bfVGJgz7V8h/K9abfeN7bp225jQ7e3ut2+ftD9GuHUh2xu7baLYvh2vjI7aPra2/dit63gsu3XBx+p8TB2Pa4Xbtwl+HE7H9W/nscJ/V0dazO75pF7jLuw8Du5W9empiBq330rdom9pS08Pxz1M683XYXn4fmW38YU0x0Mb3OFqzvb3o2mOK2S91CRLZ9u9mqSoWedE8BZV++T1alJa4NhOwr/fhT9Qp7WmfbkXwbbO9WBEx5W/3pM+tNvOsdy1ryk7O2bYnapD/jvk5PPtt5NtW2v3dN/pyOrXp7qvfu2oJ2vO7jymMUbHungSTjweY09JN1HUr55zFJjlJrT2Ca1bQ2syf6w6xHa+vt3Xxj42XA3pXxZujI77Mm1jrA1E2te5dsd1jg1d1p15ijY3kcZ6jE/eCL4F3FC/0riNk3PSSH1v0fYDbU+2q6IzwDretQ17z3t3zz6WWD3VMZxSQ83HbprCSAAF5hBzJlHF6bX+01Mx6mChh/GN70bBv2BJzOco1zoW7yG4VzyfUhdPp6G+j+M9BCSYAnMopid5wcUirIfdUL/SPYyTzIzIUv9p3jT1G/c1Sab1NzId/1eYdW2/Rfp823eI7zQm0mMoou2NjE6fPq2M9LSW7y3HY4TZT4d1pnW/xvhkWv4ermVZ6/2WZabta5mQ5f5lat2u5RBtxwz5unUMxmGMpt3zZAWNve1rT/NZXWA+Cz9pJB1Tpnye0DnW8Wwx/zNgtb8TwTaOwWHj7bcL+7v+qMbT8ezdSM4H6Opj6Jn9dGVfjscwbV+kWh1P/wnVZNr+/LQ7dSUHn/+YsdXZ2Yi9lc9Isjr+XtsK+l9h1tltJ5vtjUOM3Tq77cLtszuP1/E8YmOFWWe7nX1eLId1/rOSuvOxB43T6nyc/rUpvtO6yHykzvTrk9ZpDNxvcL9zpQh6JZ9lX64LRlxpXwtKHepKp/V2tWSkserGfUUy7uBYY4zONDYqLS01+DvQv17+2tNIxte6uK1GbfnXti649lRr7dlWYwbXnWoX6x+vL7Dftu3a5cmmHo06v+2+9p8RZhkjj++s+qpBnanXF+SzvBHWDpHVg6Gbhd93Z8d2+luqSEVaJ1shSzqvbzof++erVz7P/tvOMIz0aNSvPS1Z61ep7S8UJPvaLOxfjVrBMfb1rGT/N1id1W0dtwv9OrLY6McTGh9+vd04bGM77NLpMVlh1rc/nhV0zm6Ez5n/ayu4rk71ndYQVdtu154b6lcat3FyYb9zIorrO2KyNGl+D4/G3YzPp+O1tUofMECWp3v+jLln3uJ7XvMnldIvp3Yad96tz8t74YSeH5BL+Xw+1dbWasCAAfJ005xJVDv/UqFxG/+x07h3r35O475UHIMRuRNzpk2kc2b31c8zZ5gzkiJ/b7rkwsyeHwx6XH5WZDVs5pgZUvG9PTwa9zI+nz5rfY2wq18TtRbtikhfI8699UXqV95XJFG/Roo50ybSObNzNvUrc6ZFItWvyf1MxZE3wlIt0jgkB2+E1y+KNA69X6RvNG54Q4I7MGcQLd6bkgs1LKLFawSiRS2CaDFnEK1Eem+icRsv2aO6Nw4AbCTSGxLcgTmDqPXJklLSw8ekpLfEIfFRwwLoYdQiiBZzBlFLoPqVSyXEy+hrpG8+Ix15T80y+vjoKR2tP6mszHM1KKtPy1kK2aNa4gA//4tLU6NzjEteXOASzBlEizmDaJ2fL92xXTp1VM3GaPfHx3So9pjyB5yvMYPOb/khqU9WSxwSHzUsosX7CqLFnEG0mDOIVgLVrzRu42n0NZKukVdSvs+ndK41gs60e3GRJJ8x+vTTT9WvXz95/L89dMmLC1wigd6Q4BLMGXTF+fnS+fnyShqb61MONY22bNmi//qv/9L27dtVXV2tDRs26Prrrw+7TUVFhUpKSrRnzx7l5eXp3nvv1fz5LvysA2pYRIP6FdGiFkG0mDPoigSpX2ncAomm9cVFkuTzqclbKw0YILnsxQUukiBvSHAR5gzwuZ08eVLjx4/Xd7/7Xd1www2dxh88eFCzZ8/Wrbfeqt/85jf685//rAULFig7Ozui7QFXo35FtKhFEC3mDHopV8zgFStWqKCgQBkZGSosLNSf/vSnsPEVFRUqLCxURkaGhg0bppUrV4bErF+/XqNHj1Z6erpGjx6tDRs29NTwAQAAgCCzZs3Sgw8+qG984xsRxa9cuVKDBw/WsmXLNGrUKN1yyy363ve+p0ceeaSHRwoAAAC3invj9tlnn9XChQv1gx/8QJWVlZoyZYpmzZqlqqoq23j/2QhTpkxRZWWlFi9erLvuukvr168PxGzdulVz5szR3Llz9c4772ju3Ln65je/qTfffDNWDwsAAACI2NatWzVjxoygZTNnztS2bdt09uzZOI0KAAAA8RT3SyU8+uijuvnmm3XLLbdIkpYtW6aXX35ZTzzxhJYuXRoS3/5sBEkaNWqUtm3bpkceeSTwZ2TLli3TV7/6VZWWlkqSSktLVVFRoWXLlul3v/tdbB4YAAAAEKGamhrl5OQELcvJyVFTU5Pq6uqUm5sbsk1jY6MaG9s+iKW+vl6S5PP55PP5enbArXw+n4wxMTteoiAvzsiNPfLijNzYIy/OyI098uIs1rmJ5jhxbdyeOXNG27dv13333Re0fMaMGXr99ddtt3E6G2HVqlU6e/asUlNTtXXrVi1atCgkxt/sBQAAANzG8n9QUytjjO1yv6VLl2rJkiUhy48cOaLTp093/wBt+Hw+HT9+XMYYriPYDnlxRm7skRdn5MYeeXFGbuyRF2exzk1DQ0PEsXFt3NbV1am5udn27IKamhrbbSI5G8EpxmmfUvzPWOA3H87IjTNyY4+8OCM39siLM3Jjj7w4c/MZC242cODAkFq1trZWKSkpysrKst2mtLRUJSUlgfv19fXKz89Xdna2MjMze3S8fj6fT5ZlKTs7mx8C2yEvzsiNPfLijNzYIy/OyI098uIs1rnJyMiIODbul0qQ7M8ucDqzwCm+4/Jo9xnvMxb4zYczcuOM3NgjL87IjT3y4ozc2CMvztx8xoKbFRUV6YUXXghaVlZWpokTJyo1NdV2m/T0dKWnp4cs93g8MZ2XlmXF/JiJgLw4Izf2yIszcmOPvDgjN/bIi7NY5iaaY8S1cdu/f395vV7bsws6njHrF8nZCE4xTvuU4n/GAr/5cEZunJEbe+TFGbmxR16ckRt75MWZm89YiKUTJ05o//79gfsHDx7Ujh071K9fPw0ePFilpaX65JNPtHbtWknS/Pnz9fjjj6ukpES33nqrtm7dqlWrVvH5DAAAAEksro3btLQ0FRYWatOmTfr6178eWL5p0yZdd911tttEcjZCUVGRNm3aFHSd27KyMk2ePNlxLG44Y4HffDgjN87IjT3y4ozc2CMvzsiNPfLizK1nLMTStm3bNG3atMB9/wkC8+bN05o1a1RdXa2qqqrA+oKCAm3cuFGLFi3Sz3/+c+Xl5Wn58uWBD98FAABA8on7pRJKSko0d+5cTZw4UUVFRXryySdVVVWl+fPnS1KXzka4++67ddVVV+mhhx7Sddddp+eee06vvPKKXnvttbg8RgAAACSXqVOnBi7nZWfNmjUhy4qLi/X222/34KgAAACQSOLeuJ0zZ46OHj2qBx54QNXV1RozZow2btyoIUOGSFKXzkaYPHmy1q1bpx/+8If60Y9+pOHDh+vZZ5/VFVdcEfPHBwAAAAAAAADRinvjVpIWLFigBQsW2K7r6tkIN954o2688cYuj8l/hkR9fX2X9xENn8+nhoYGZWRkuPZP/uKF3DgjN/bIizNyY4+8OCM39siLs1jnxl+rhTu7NVnEun6V+F5wQl6ckRt75MUZubFHXpyRG3vkxZmb61dXNG7dyP8Jxfn5+XEeCQAAADrT0NCgvn37xnsYcUX9CgAAkDgiqV8tw+kJtnw+n/72t7/pvPPOk2VZPX68+vp65efn69ChQ8rMzOzx4yUScuOM3NgjL87IjT3y4ozc2CMvzmKdG2OMGhoalJeXl/Rnj8S6fpX4XnBCXpyRG3vkxRm5sUdenJEbe+TFmZvrV864deDxeDRo0KCYHzczM5NvIAfkxhm5sUdenJEbe+TFGbmxR16cxTI3yX6mrV+86leJ7wUn5MUZubFHXpyRG3vkxRm5sUdenLmxfk3u0xIAAAAAAAAAwIVo3AIAAAAAAACAy9C4dYn09HTdf//9Sk9Pj/dQXIfcOCM39siLM3Jjj7w4Izf2yIszcpNceL7tkRdn5MYeeXFGbuyRF2fkxh55cebm3PDhZAAAAAAAAADgMpxxCwAAAAAAAAAuQ+MWAAAAAAAAAFyGxi0AAAAAAAAAuAyN2xjZsmWLrr32WuXl5cmyLP3v//5vp9tUVFSosLBQGRkZGjZsmFauXNnzA42DaHOzefNmWZYVctu7d29sBhwDS5cu1eWXX67zzjtPAwYM0PXXX699+/Z1ul0yzJmu5CYZ5owkPfHEExo3bpwyMzOVmZmpoqIi/d///V/YbZJhzkSbl2SZLx0tXbpUlmVp4cKFYeOSYc50FElukmXe/OQnPwl5jAMHDgy7TTLOmd6C+tUZ9as9alh71K/OqF/tUb9GhvrVGfVrm0SvX2ncxsjJkyc1fvx4Pf744xHFHzx4ULNnz9aUKVNUWVmpxYsX66677tL69et7eKSxF21u/Pbt26fq6urA7aKLLuqhEcZeRUWFbr/9dr3xxhvatGmTmpqaNGPGDJ08edJxm2SZM13JjV9vnjOSNGjQIP3nf/6ntm3bpm3btukrX/mKrrvuOu3Zs8c2PlnmTLR58evt86W9t956S08++aTGjRsXNi5Z5kx7kebGLxnmzSWXXBL0GHft2uUYm4xzpjehfnVG/WqPGtYe9asz6ld71K+do351Rv0aKqHrV4OYk2Q2bNgQNubee+81I0eODFp22223mUmTJvXgyOIvktyUl5cbSeazzz6LyZjcoLa21kgyFRUVjjHJOmciyU0yzhm/Cy64wDz11FO265J1zhgTPi/JNl8aGhrMRRddZDZt2mSKi4vN3Xff7RibbHMmmtwky7y5//77zfjx4yOOT7Y505tRvzqjfnVGDWuP+jU86ld71K9tqF+dUb+GSvT6lTNuXWrr1q2aMWNG0LKZM2dq27ZtOnv2bJxG5S4TJkxQbm6upk+frvLy8ngPp0cdP35cktSvXz/HmGSdM5Hkxi+Z5kxzc7PWrVunkydPqqioyDYmGedMJHnxS5b5cvvtt+vqq6/WP/zDP3Qam2xzJprc+CXDvPnggw+Ul5engoICfetb39KBAwccY5NtziQ7nu/OJcNrRHvUsPaoX+1Rv9qjfg1F/eqM+tVeItevKTE/IiJSU1OjnJycoGU5OTlqampSXV2dcnNz4zSy+MvNzdWTTz6pwsJCNTY26te//rWmT5+uzZs366qrror38LqdMUYlJSW68sorNWbMGMe4ZJwzkeYmmebMrl27VFRUpNOnT+sLX/iCNmzYoNGjR9vGJtOciSYvyTRf1q1bp7fffltvvfVWRPHJNGeizU2yzJsrrrhCa9eu1cUXX6zDhw/rwQcf1OTJk7Vnzx5lZWWFxCfTnAHPdzjJ8hrRHjWsPerXUNSv9qhf7VG/OqN+tZfo9SuNWxezLCvovjHGdnmyGTFihEaMGBG4X1RUpEOHDumRRx7pVS8ufnfccYd27typ1157rdPYZJszkeYmmebMiBEjtGPHDh07dkzr16/XvHnzVFFR4VjkJcuciSYvyTJfDh06pLvvvltlZWXKyMiIeLtkmDNdyU2yzJtZs2YFvh47dqyKioo0fPhw/epXv1JJSYntNskwZ9CG59tesrxGtEcNa4/6NRT1qz3q11DUr86oX50lev3KpRJcauDAgaqpqQlaVltbq5SUFNvfCCS7SZMm6YMPPoj3MLrdnXfeqeeff17l5eUaNGhQ2NhkmzPR5MZOb50zaWlp+uIXv6iJEydq6dKlGj9+vH7605/axibTnIkmL3Z643zZvn27amtrVVhYqJSUFKWkpKiiokLLly9XSkqKmpubQ7ZJljnTldzY6Y3zpqNzzz1XY8eOdXycyTJn0ILnOzq9+TWCGtYe9as96ld71K+hqF+dUb9GLtHqV864damioiK98MILQcvKyso0ceJEpaamxmlU7lVZWdmr/sTBGKM777xTGzZs0ObNm1VQUNDpNskyZ7qSGzu9bc44McaosbHRdl2yzBk74fJipzfOl+nTp4d8mup3v/tdjRw5Uv/+7/8ur9cbsk2yzJmu5MZOb5w3HTU2Nuq9997TlClTbNcny5xBC57v6PTG1whqWHvUr9GhfrVH/Ur9Gg71a+QSrn6N5SehJbOGhgZTWVlpKisrjSTz6KOPmsrKSvPRRx8ZY4y57777zNy5cwPxBw4cMH369DGLFi0y7777rlm1apVJTU01v//97+P1EHpMtLl57LHHzIYNG8z7779vdu/ebe677z4jyaxfvz5eD6Hb/du//Zvp27ev2bx5s6murg7cTp06FYhJ1jnTldwkw5wxxpjS0lKzZcsWc/DgQbNz506zePFi4/F4TFlZmTEmeedMtHlJlvlip+MnzybrnLHTWW6SZd58//vfN5s3bzYHDhwwb7zxhrnmmmvMeeedZz788ENjDHOmt6F+dUb9ao8a1h71qzPqV3vUr5GjfnVG/doi0etXGrcxUl5ebiSF3ObNm2eMMWbevHmmuLg4aJvNmzebCRMmmLS0NDN06FDzxBNPxH7gMRBtbh566CEzfPhwk5GRYS644AJz5ZVXmpdeeik+g+8hdvmQZFavXh2ISdY505XcJMOcMcaY733ve2bIkCEmLS3NZGdnm+nTpweKO2OSd85Em5dkmS92OhZ3yTpn7HSWm2SZN3PmzDG5ubkmNTXV5OXlmW984xtmz549gfXMmd6F+tUZ9as9alh71K/OqF/tUb9GjvrVGfVri0SvXy1jWq+wCwAAAAAAAABwBT6cDAAAAAAAAABchsYtAAAAAAAAALgMjVsAAAAAAAAAcBkatwAAAAAAAADgMjRuAQAAAAAAAMBlaNwCAAAAAAAAgMvQuAUAAAAAAAAAl6FxCwAAAAAAAAAuQ+MWAFzizjvv1GWXXab6+vp4DwUAAADoFPUrAPSslHgPAAAg/frXv1ZZWZlee+01ZWZmxns4AAAAQFjUrwDQ8yxjjIn3IAAAAAAAAAAAbbhUAgDEyZo1a2RZluNt8+bN8R4iAAAAEED9CgCxxaUSACDOVq9erZEjR4YsHz16dBxGAwAAAIRH/QoAsUHjFgDibMyYMZo4cWK8hwEAAABEhPoVAGKDSyUAgMtZlqU77rhDv/jFL3TxxRcrPT1do0eP1rp160Jid+/ereuuu04XXHCBMjIydOmll+pXv/pVSNzevXv1ta99TX369FH//v01f/58vfDCCyF/4jZ06FDddNNNIdtPnTpVU6dODVpWX1+ve+65RwUFBUpLS9OFF16ohQsX6uTJk583BQAAAEgg1K8A0D044xYA4qy5uVlNTU1ByyzLktfrDdx//vnnVV5ergceeEDnnnuuVqxYoX/6p39SSkqKbrzxRknSvn37NHnyZA0YMEDLly9XVlaWfvOb3+imm27S4cOHde+990qSDh8+rOLiYqWmpmrFihXKycnRM888ozvuuKPLj+HUqVMqLi7Wxx9/rMWLF2vcuHHas2ePfvzjH2vXrl165ZVXZFlWl/cPAAAA96B+BYDYoHELAHE2adKkkGVerzeoGK6rq9Nbb72lnJwcSdLs2bM1ZswYlZaWBgrfn/zkJzpz5ozKy8uVn58fiDt27JiWLFmi2267TX379tVjjz2mI0eOqLKyUuPHj5ckzZo1SzNmzFBVVVWXHsPy5cu1c+dOvfnmm4E/m5s+fbouvPBC3XjjjfrDH/6gWbNmdWnfAAAAcBfqVwCIDS6VAABxtnbtWr311ltBtzfffDMoZvr06YGiV2opjOfMmaP9+/fr448/liS9+uqrmj59eqDo9bvpppt06tQpbd26VZJUXl6uSy65JFD0+v3zP/9zlx/Diy++qDFjxujSSy9VU1NT4DZz5kw+YRgAAKCXoX4FgNjgjFsAiLNRo0Z1+uEOAwcOdFx29OhRDRo0SEePHlVubm5IXF5eXiDO/39BQUFEx4jU4cOHtX//fqWmptqur6ur6/K+AQAA4C7UrwAQGzRuASAB1NTUOC7LysoK/F9dXR0S97e//U2S1L9//0BcuP21l5GRocbGxpDldXV1gf35933OOefo6aefth1/+1gAAAD0ftSvAPD5cakEAEgAf/zjH3X48OHA/ebmZj377LMaPny4Bg0aJKnlz9FeffXVQKHrt3btWvXp0ydwLbJp06Zpz549euedd4Lifvvb34Ycd+jQodq5c2fQsvfff1/79u0LWnbNNdfor3/9q7KysjRx4sSQ29ChQ7v82AEAAJB4qF8B4PPjjFsAiLPdu3eHfCqvJA0fPlzZ2dmSWn7j/5WvfEU/+tGPAp/Ku3fvXq1bty4Qf//99+vFF1/UtGnT9OMf/1j9+vXTM888o5deekkPP/yw+vbtK0lauHChnn76aV199dV68MEHA5/Ku3fv3pAxzJ07V9/+9re1YMEC3XDDDfroo4/08MMPB8blt3DhQq1fv15XXXWVFi1apHHjxsnn86mqqkplZWX6/ve/ryuuuKI70wYAAIA4oX4FgBgxAIC4WL16tZHkePvlL39pjDFGkrn99tvNihUrzPDhw01qaqoZOXKkeeaZZ0L2uWvXLnPttdeavn37mrS0NDN+/HizevXqkLh3333XfPWrXzUZGRmmX79+5uabbzbPPfeckWTKy8sDcT6fzzz88MNm2LBhJiMjw0ycONG8+uqrpri42BQXFwft88SJE+aHP/yhGTFihElLSzN9+/Y1Y8eONYsWLTI1NTXdmToAAADEAfUrAMSWZYwxsW4WAwAiZ1mWbr/9dj3++OM9epzNmzdr2rRpKi8v19SpU3v0WAAAAOi9qF8BoHtwjVsAAAAAAAAAcBkatwAAAAAAAADgMlwqAQAAAAAAAABchjNuAQAAAAAAAMBlaNwCAAAAAAAAgMvQuAUAAAAAAAAAl6FxCwAAAAAAAAAuQ+MWAAAAAAAAAFyGxi0AAAAAAAAAuAyNWwAAAAAAAABwGRq3AAAAAAAAAOAyNG4BAAAAAAAAwGX+P4Vrf9/DzVeaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Analyse des r√©sultats Post-Training:\n",
      "   - Am√©lioration train: 0.3460\n",
      "   - Am√©lioration val:   0.0008\n",
      "   - Gap train/val:      0.0000\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 9: Visualisation de la Loss\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Courbe de loss\n",
    "axes[0].plot(history['epochs'], history['train_loss'], marker='o', label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['epochs'], history['val_loss'], marker='s', label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('√âpoque', fontsize=12)\n",
    "axes[0].set_ylabel('Cross-Entropy Loss', fontsize=12)\n",
    "axes[0].set_title('üìâ Courbe d\\'Apprentissage (Post-Training)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Perplexity\n",
    "perplexity_train = [np.exp(loss) for loss in history['train_loss']]\n",
    "perplexity_val = [np.exp(loss) for loss in history['val_loss']]\n",
    "axes[1].plot(history['epochs'], perplexity_train, marker='o', label='Train Perplexity', linewidth=2)\n",
    "axes[1].plot(history['epochs'], perplexity_val, marker='s', label='Val Perplexity', linewidth=2)\n",
    "axes[1].set_xlabel('√âpoque', fontsize=12)\n",
    "axes[1].set_ylabel('Perplexity', fontsize=12)\n",
    "axes[1].set_title('üìä Perplexit√© (Post-Training)', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyse\n",
    "print(\"\\nüìà Analyse des r√©sultats Post-Training:\")\n",
    "improvement_train = history['train_loss'][0] - history['train_loss'][-1]\n",
    "improvement_val = history['val_loss'][0] - history['val_loss'][-1]\n",
    "print(f\"   - Am√©lioration train: {improvement_train:.4f}\")\n",
    "print(f\"   - Am√©lioration val:   {improvement_val:.4f}\")\n",
    "print(f\"   - Gap train/val:      {history['val_loss'][-1] - history['train_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb79314",
   "metadata": {},
   "source": [
    "## üîπ Partie 8 : Tests de G√©n√©ration avec Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7de34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ TESTS DE G√âN√âRATION AVEC INSTRUCTIONS\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Test 1: Write a function to check if a number is prime\n",
      "======================================================================\n",
      "\n",
      "<instruction> Write a function to check if a number is prime <reasoning> Check if 5 <answer> def is_odd(n):\\n    return n % 2 == 1<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 2: Create a function to reverse a list\n",
      "======================================================================\n",
      "\n",
      "<instruction> Create a function to reverse a list <reasoning> Check each number <answer> def is_string(s):\\n    return                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 3: Implement binary search algorithm\n",
      "======================================================================\n",
      "\n",
      "<instruction> Implement binary search algorithm <reasoning> Iterate and sum numbers divisible by                                                                                                   prime):\\n):\\\\n    return)\\n):\\\\n    return\\n    return even):\\n    returnint i in range(1)\\n    return intint i in range*n    return [lst)*n    return numbers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "\n",
      "\n",
      "======================================================================\n",
      "Test 4: Write a function to calculate Fibonacci sequence\n",
      "======================================================================\n",
      "\n",
      "<instruction> Write a function to calculate Fibonacci sequence <reasoning> Compare list with 5*n^2+4 or 5*n^2-4 is perfect square <answer> def is_fibonacci(n):\\n    return sum(n    return int(math.sqrt(5*n*n + 4))**2 == 5*n*n + 4 or int(math.sqrt(5*n*n - 4))**2 == 5*n*n - 4<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Tests de g√©n√©ration termin√©s\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 10: Tests de G√©n√©ration\n",
    "\n",
    "def generate_from_instruction(instruction, max_tokens=150, temperature=0.7, top_k=40):\n",
    "    \"\"\"G√©n√®re du code √† partir d'une instruction\"\"\"\n",
    "    model.eval()\n",
    "    prompt = f\"<instruction> {instruction} <reasoning>\"\n",
    "    input_ids = torch.tensor([tokenizer.encode(prompt)], device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids, \n",
    "            max_new_tokens=max_tokens, \n",
    "            temperature=temperature, \n",
    "            top_k=top_k\n",
    "        )\n",
    "    \n",
    "    generated = tokenizer.decode(output_ids[0].tolist())\n",
    "    model.train()\n",
    "    return generated\n",
    "\n",
    "# Tests\n",
    "test_instructions = [\n",
    "    \"Write a function to check if a number is prime\",\n",
    "    \"Create a function to reverse a list\",\n",
    "    \"Implement binary search algorithm\",\n",
    "    \"Write a function to calculate Fibonacci sequence\",\n",
    "]\n",
    "\n",
    "print(\"üéØ TESTS DE G√âN√âRATION AVEC INSTRUCTIONS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, instruction in enumerate(test_instructions, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Test {i}: {instruction}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    result = generate_from_instruction(instruction, max_tokens=200, temperature=0.7)\n",
    "    print(result)\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Tests de g√©n√©ration termin√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc58176",
   "metadata": {},
   "source": [
    "## üîπ Partie 9 : Sauvegarde Finale du Mod√®le Post-Entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e7408ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üíæ SAUVEGARDE FINALE DU MOD√àLE POST-ENTRA√éN√â\n",
      "======================================================================\n",
      "\n",
      "üìä Analyse des checkpoints SFT...\n",
      "   √âpoque 1: Val Loss = 0.0121\n",
      "   √âpoque 2: Val Loss = 0.0116\n",
      "   √âpoque 3: Val Loss = 0.0115\n",
      "   √âpoque 4: Val Loss = 0.0115\n",
      "   √âpoque 5: Val Loss = 0.0117\n",
      "\n",
      "üèÜ Meilleur mod√®le SFT : √âpoque 4 (Val Loss = 0.0115)\n",
      "üíæ Mod√®le final SFT sauvegard√© : models/post_training/model_sft_FINAL.pt\n",
      "‚ö° Poids seuls sauvegard√©s : models/post_training/model_weights_only.pt\n",
      "üî§ Tokenizer mis √† jour sauvegard√© : models/post_training/tokenizer/\n",
      "\n",
      "======================================================================\n",
      "üì¶ R√âSUM√â DES ARTEFACTS CR√â√âS\n",
      "======================================================================\n",
      "‚úÖ Checkpoints SFT : models/post_training/model_sft_epoch_[1-5].pt\n",
      "‚úÖ Mod√®le final SFT: models/post_training/model_sft_FINAL.pt\n",
      "‚úÖ Poids seuls     : models/post_training/model_weights_only.pt\n",
      "‚úÖ Tokenizer SFT   : models/post_training/tokenizer/\n",
      "\n",
      "======================================================================\n",
      "üìå UTILISATION DU MOD√àLE POST-ENTRA√éN√â\n",
      "======================================================================\n",
      "\n",
      "# Charger le mod√®le SFT\n",
      "checkpoint = torch.load('models/post_training/model_sft_FINAL.pt')\n",
      "model.load_state_dict(checkpoint['model_state_dict'])\n",
      "tokenizer = AutoTokenizer.from_pretrained('models/post_training/tokenizer')\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 11: Sauvegarde Finale\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üíæ SAUVEGARDE FINALE DU MOD√àLE POST-ENTRA√éN√â\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Analyser les checkpoints SFT\n",
    "print(\"\\nüìä Analyse des checkpoints SFT...\")\n",
    "best_epoch = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    checkpoint_path = f\"models/post_training/model_sft_epoch_{epoch}.pt\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        ckpt = torch.load(checkpoint_path)\n",
    "        val_loss = ckpt['history']['val_loss'][-1]\n",
    "        print(f\"   √âpoque {epoch}: Val Loss = {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le SFT : √âpoque {best_epoch} (Val Loss = {best_val_loss:.4f})\")\n",
    "\n",
    "# Charger le meilleur checkpoint\n",
    "best_checkpoint_path = f\"models/post_training/model_sft_epoch_{best_epoch}.pt\"\n",
    "best_checkpoint = torch.load(best_checkpoint_path)\n",
    "\n",
    "# Sauvegarder le mod√®le final\n",
    "final_model_path = \"models/post_training/model_sft_FINAL.pt\"\n",
    "torch.save({\n",
    "    'epoch': best_checkpoint['epoch'],\n",
    "    'model_state_dict': best_checkpoint['model_state_dict'],\n",
    "    'optimizer_state_dict': best_checkpoint['optimizer_state_dict'],\n",
    "    'scheduler_state_dict': best_checkpoint['scheduler_state_dict'],\n",
    "    'history': best_checkpoint['history'],\n",
    "    'config': best_checkpoint['config'],\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'selected_from_epoch': best_epoch,\n",
    "    'training_stage': 'post-training'\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"üíæ Mod√®le final SFT sauvegard√© : {final_model_path}\")\n",
    "\n",
    "# Sauvegarder les poids seuls\n",
    "model_weights_path = \"models/post_training/model_weights_only.pt\"\n",
    "torch.save(best_checkpoint['model_state_dict'], model_weights_path)\n",
    "print(f\"‚ö° Poids seuls sauvegard√©s : {model_weights_path}\")\n",
    "\n",
    "# Sauvegarder le tokenizer mis √† jour\n",
    "tokenizer.save_pretrained(\"models/post_training/tokenizer\")\n",
    "print(f\"üî§ Tokenizer mis √† jour sauvegard√© : models/post_training/tokenizer/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì¶ R√âSUM√â DES ARTEFACTS CR√â√âS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Checkpoints SFT : models/post_training/model_sft_epoch_[1-{N_EPOCHS}].pt\")\n",
    "print(f\"‚úÖ Mod√®le final SFT: {final_model_path}\")\n",
    "print(f\"‚úÖ Poids seuls     : {model_weights_path}\")\n",
    "print(f\"‚úÖ Tokenizer SFT   : models/post_training/tokenizer/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìå UTILISATION DU MOD√àLE POST-ENTRA√éN√â\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n# Charger le mod√®le SFT\")\n",
    "print(\"checkpoint = torch.load('models/post_training/model_sft_FINAL.pt')\")\n",
    "print(\"model.load_state_dict(checkpoint['model_state_dict'])\")\n",
    "print(\"tokenizer = AutoTokenizer.from_pretrained('models/post_training/tokenizer')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff28715",
   "metadata": {},
   "source": [
    "## üîπ Partie 10 : Comparaison Pre-Training vs Post-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91cfad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä COMPARAISON PRE-TRAINING vs POST-TRAINING\n",
      "======================================================================\n",
      "['tok_emb.weight', 'pos_emb.weight', 'blocks.0.ln1.weight', 'blocks.0.ln1.bias', 'blocks.0.attn.mask', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.ln2.weight', 'blocks.0.ln2.bias', 'blocks.0.ff.0.weight', 'blocks.0.ff.0.bias', 'blocks.0.ff.2.weight', 'blocks.0.ff.2.bias', 'blocks.1.ln1.weight', 'blocks.1.ln1.bias', 'blocks.1.attn.mask', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.ln2.weight', 'blocks.1.ln2.bias', 'blocks.1.ff.0.weight', 'blocks.1.ff.0.bias', 'blocks.1.ff.2.weight', 'blocks.1.ff.2.bias', 'blocks.2.ln1.weight', 'blocks.2.ln1.bias', 'blocks.2.attn.mask', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.ln2.weight', 'blocks.2.ln2.bias', 'blocks.2.ff.0.weight', 'blocks.2.ff.0.bias', 'blocks.2.ff.2.weight', 'blocks.2.ff.2.bias', 'blocks.3.ln1.weight', 'blocks.3.ln1.bias', 'blocks.3.attn.mask', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.ln2.weight', 'blocks.3.ln2.bias', 'blocks.3.ff.0.weight', 'blocks.3.ff.0.bias', 'blocks.3.ff.2.weight', 'blocks.3.ff.2.bias', 'blocks.4.ln1.weight', 'blocks.4.ln1.bias', 'blocks.4.attn.mask', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.ln2.weight', 'blocks.4.ln2.bias', 'blocks.4.ff.0.weight', 'blocks.4.ff.0.bias', 'blocks.4.ff.2.weight', 'blocks.4.ff.2.bias', 'blocks.5.ln1.weight', 'blocks.5.ln1.bias', 'blocks.5.attn.mask', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.ln2.weight', 'blocks.5.ln2.bias', 'blocks.5.ff.0.weight', 'blocks.5.ff.0.bias', 'blocks.5.ff.2.weight', 'blocks.5.ff.2.bias', 'blocks.6.ln1.weight', 'blocks.6.ln1.bias', 'blocks.6.attn.mask', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.ln2.weight', 'blocks.6.ln2.bias', 'blocks.6.ff.0.weight', 'blocks.6.ff.0.bias', 'blocks.6.ff.2.weight', 'blocks.6.ff.2.bias', 'blocks.7.ln1.weight', 'blocks.7.ln1.bias', 'blocks.7.attn.mask', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.ln2.weight', 'blocks.7.ln2.bias', 'blocks.7.ff.0.weight', 'blocks.7.ff.0.bias', 'blocks.7.ff.2.weight', 'blocks.7.ff.2.bias', 'ln_f.weight', 'ln_f.bias', 'head.weight']\n",
      "\n",
      "üìà M√©triques finales :\n",
      "\n",
      "Pre-Training (Base Model):\n",
      "   - Validation Loss : None\n",
      "   - Objectif        : Apprendre la syntaxe Python\n",
      "   - Dataset         : Code brut (100k documents)\n",
      "\n",
      "Post-Training (SFT Model):\n",
      "   - Validation Loss : 0.0115\n",
      "   - Objectif        : Suivre des instructions\n",
      "   - Dataset         : Paires instruction-code (10k exemples)\n",
      "\n",
      "üéØ Am√©lioration :\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Post-Training termin√© avec succ√®s !\n",
      "üéâ Le mod√®le peut maintenant suivre des instructions et g√©n√©rer du code structur√© !\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 12: Comparaison des Mod√®les\n",
    "\n",
    "print(\"üìä COMPARAISON PRE-TRAINING vs POST-TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Charger les m√©triques du pre-training\n",
    "pretrain_checkpoint = torch.load(\"models/pre_training/model_final.pt\")\n",
    "print(list(checkpoint.keys()))\n",
    "pretrain_val_loss = pretrain_checkpoint.get('val_loss', None)\n",
    "\n",
    "print(f\"\\nüìà M√©triques finales :\")\n",
    "print(f\"\\nPre-Training (Base Model):\")\n",
    "print(f\"   - Validation Loss : {pretrain_val_loss}\")\n",
    "print(f\"   - Objectif        : Apprendre la syntaxe Python\")\n",
    "print(f\"   - Dataset         : Code brut (100k documents)\")\n",
    "\n",
    "print(f\"\\nPost-Training (SFT Model):\")\n",
    "print(f\"   - Validation Loss : {best_val_loss:.4f}\")\n",
    "print(f\"   - Objectif        : Suivre des instructions\")\n",
    "print(f\"   - Dataset         : Paires instruction-code (10k exemples)\")\n",
    "\n",
    "print(f\"\\nüéØ Am√©lioration :\")\n",
    "if isinstance(pretrain_val_loss, float):\n",
    "    improvement = pretrain_val_loss - best_val_loss\n",
    "    print(f\"   - R√©duction de loss : {improvement:.4f} ({improvement/pretrain_val_loss*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Post-Training termin√© avec succ√®s !\")\n",
    "print(\"üéâ Le mod√®le peut maintenant suivre des instructions et g√©n√©rer du code structur√© !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e6632",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ R√©sum√© du Post-Training\n",
    "\n",
    "### ‚úÖ Objectifs Accomplis\n",
    "\n",
    "1. **R√©cup√©ration** : Mod√®le et tokenizer du Pre-Training charg√©s\n",
    "2. **Dataset SFT** : 10,000 exemples instruction‚Üíreasoning‚Üícode charg√©s\n",
    "3. **Tokens sp√©ciaux** : `<instruction>`, `<reasoning>`, `<answer>` ajout√©s\n",
    "4. **Fine-Tuning** : 5 √©poques d'entra√Ænement supervis√©\n",
    "5. **Sauvegarde** : Meilleur mod√®le SFT sauvegard√©\n",
    "\n",
    "### üìä Architecture Finale\n",
    "\n",
    "```\n",
    "Mini-GPT Post-Entra√Æn√©\n",
    "‚îú‚îÄ‚îÄ Vocabulaire : 50,260 tokens (GPT-2 + 3 tokens sp√©ciaux)\n",
    "‚îú‚îÄ‚îÄ Architecture : 8 layers, 8 heads, 512 dims\n",
    "‚îú‚îÄ‚îÄ Param√®tres  : ~0.X M\n",
    "‚îî‚îÄ‚îÄ Capacit√©s   : Suivre instructions, raisonner, coder\n",
    "```\n",
    "\n",
    "### üöÄ Prochaines √âtapes\n",
    "\n",
    "Le mod√®le peut maintenant √™tre utilis√© pour :\n",
    "- **G√©n√©ration de code** √† partir d'instructions naturelles\n",
    "- **RLHF** : Optimisation par feedback humain\n",
    "- **D√©ploiement** : API de g√©n√©ration de code\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Fichiers Cr√©√©s\n",
    "\n",
    "```\n",
    "models/post_training/\n",
    "‚îú‚îÄ‚îÄ mini_gpt_sft_epoch_[1-5].pt    # Checkpoints par √©poque\n",
    "‚îú‚îÄ‚îÄ mini_gpt_sft_FINAL.pt          # ‚úÖ Meilleur mod√®le (√† utiliser)\n",
    "‚îú‚îÄ‚îÄ mini_gpt_sft_weights_only.pt   # ‚úÖ Poids seuls (l√©ger)\n",
    "‚îî‚îÄ‚îÄ tokenizer/                      # ‚úÖ Tokenizer avec tokens sp√©ciaux\n",
    "    ‚îú‚îÄ‚îÄ tokenizer_config.json\n",
    "    ‚îú‚îÄ‚îÄ vocab.json\n",
    "    ‚îî‚îÄ‚îÄ merges.txt\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abcd30",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aapl_ql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
